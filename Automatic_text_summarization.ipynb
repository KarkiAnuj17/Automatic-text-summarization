{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KarkiAnuj17/Automatic-text-summarization/blob/main/Automatic_text_summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "HUshmJtq0hCv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9ed6089-f523-469d-d886-ab56ad5e0db2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "EtxIWDza0kMp"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/dataset.zip\", 'r')\n",
        "zip_ref.extractall(\"/content/dataset\")\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "qo35kKPv0kRP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import cudf\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from nltk import pos_tag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "_oX8kZ610kT9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d4e84bb-5c93-41a9-8b38-f921fc70a3f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['id', 'article', 'highlights'], dtype='object')\n",
            "(11490, 3)\n"
          ]
        }
      ],
      "source": [
        "path=\"/content/dataset/dataset/test.csv\"\n",
        "df=pd.read_csv(path)\n",
        "print(df.columns)\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "wufX14cj0kWa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f04e33aa-6e01-4109-911b-ac983c617944"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6lN5tja0kYz",
        "outputId": "48d9a5d2-8cb5-4975-f6b0-c71fec719a10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11490/11490 [07:36<00:00, 25.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                         id  \\\n",
            "0  92c514c913c0bdfe25341af9fd72b29db544099b   \n",
            "1  2003841c7dc0e7c5b1a248f9cd536d727f27a45a   \n",
            "2  91b7d2311527f5c2b63a65ca98d21d9c92485149   \n",
            "3  caabf9cbdf96eb1410295a673e953d304391bfbb   \n",
            "4  3da746a7d9afcaa659088c8366ef6347fe6b53ea   \n",
            "\n",
            "                                             article  \\\n",
            "0  Ever noticed how plane seats appear to be gett...   \n",
            "1  A drunk teenage boy had to be rescued by secur...   \n",
            "2  Dougie Freedman is on the verge of agreeing a ...   \n",
            "3  Liverpool target Neto is also wanted by PSG an...   \n",
            "4  Bruce Jenner will break his silence in a two-h...   \n",
            "\n",
            "                                          highlights  \\\n",
            "0  Experts question if  packed out planes are put...   \n",
            "1  Drunk teenage boy climbed into lion enclosure ...   \n",
            "2  Nottingham Forest are close to extending Dougi...   \n",
            "3  Fiorentina goalkeeper Neto has been linked wit...   \n",
            "4  Tell-all interview with the reality TV star, 6...   \n",
            "\n",
            "                                      processed_text  \n",
            "0  [[ever, notice, plane, seat, appear, get, smal...  \n",
            "1  [[drunk, teenage, boy, rescue, security, jump,...  \n",
            "2  [[dougie, freedman, verge, agree, new, deal, r...  \n",
            "3  [[liverpool, target, neto, also, want, psg, cl...  \n",
            "4  [[bruce, jenner, break, silence, interview, di...  \n"
          ]
        }
      ],
      "source": [
        "def get_wordnet_pos(treebank_tag):\n",
        "    # Map POS tag to WordNet POS tag\n",
        "    if treebank_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif treebank_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif treebank_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif treebank_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Split text into sentences\n",
        "    sentences = sent_tokenize(text)\n",
        "\n",
        "    # Initialize lemmatizer\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "    # Get English stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    # Preprocess each sentence\n",
        "    processed_sentences = []\n",
        "    for sentence in sentences:\n",
        "        # Tokenize words in the sentence\n",
        "        words = word_tokenize(sentence)\n",
        "\n",
        "        # Get POS tags\n",
        "        pos_tags = pos_tag(words)\n",
        "\n",
        "        # Lemmatize and remove stopwords\n",
        "        processed_words = []\n",
        "        for word, pos in pos_tags:\n",
        "            if word.lower() not in stop_words and word.isalnum():\n",
        "                lemmatized_word = lemmatizer.lemmatize(word.lower(), get_wordnet_pos(pos))\n",
        "                processed_words.append(lemmatized_word)\n",
        "\n",
        "        # Append processed sentence\n",
        "        processed_sentences.append(processed_words)\n",
        "\n",
        "    return processed_sentences\n",
        "\n",
        "def preprocess_csv(file_path, text_column):\n",
        "    # Read the CSV file into a cuDF DataFrame\n",
        "    df = cudf.read_csv(file_path)\n",
        "\n",
        "    # Convert text column to a pandas Series for processing with NLTK\n",
        "    text_series = df[text_column].to_pandas()\n",
        "\n",
        "    # Apply preprocessing to the text column with progress bar\n",
        "    processed_text = text_series.progress_apply(preprocess_text)\n",
        "\n",
        "    # Convert the processed text back to a cuDF DataFrame\n",
        "    df['processed_text'] = cudf.from_pandas(processed_text)\n",
        "\n",
        "    return df\n",
        "\n",
        "# Enable the tqdm progress_apply\n",
        "tqdm.pandas()\n",
        "\n",
        "file_path = '/content/dataset/dataset/test.csv'\n",
        "text_column = 'article'\n",
        "processed_df = preprocess_csv(file_path, text_column)\n",
        "\n",
        "# Display the processed DataFrame\n",
        "print(processed_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cupy as cp\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Cosine Similarity Function\n",
        "def cosine_similarity_matrix(matrix):\n",
        "    matrix = cp.array(matrix)\n",
        "    dot_product = cp.dot(matrix, matrix.T)  # Compute dot product\n",
        "    norm = cp.linalg.norm(matrix, axis=1)  # Compute norm (magnitude) of each vector\n",
        "    similarity_matrix = dot_product / (cp.outer(norm, norm) + 1e-10)  # Cosine similarity\n",
        "    return similarity_matrix\n",
        "\n",
        "# Vectorization Function using TF-IDF\n",
        "def vectorize_sentences_with_tfidf(sentences):\n",
        "    vectorizer = TfidfVectorizer(stop_words='english')  # Optional: Remove stopwords\n",
        "    term_doc_matrix_cpu = vectorizer.fit_transform(sentences)  # Compute the TF-IDF matrix\n",
        "\n",
        "    # Convert the sparse matrix to a dense NumPy array\n",
        "    term_doc_matrix_cpu = term_doc_matrix_cpu.toarray()\n",
        "\n",
        "    # Convert to CuPy array for GPU acceleration\n",
        "    term_doc_matrix = cp.array(term_doc_matrix_cpu)\n",
        "\n",
        "    return term_doc_matrix\n",
        "\n",
        "# Function to Compute Similarity for Articles\n",
        "def compute_similarity_for_articles(df, text_column='processed_text'):\n",
        "    text_series = df[text_column].to_pandas()  # Get text data from DataFrame\n",
        "    similarity_matrices = []\n",
        "\n",
        "    # Iterate over each article's processed text\n",
        "    for index, processed_text in tqdm(text_series.items(), total=len(text_series), desc=\"Processing Articles\"):\n",
        "        processed_sentences = [' '.join(sentence) for sentence in processed_text]  # Join words into sentences\n",
        "\n",
        "        # Vectorize sentences using TF-IDF approach\n",
        "        term_doc_matrix = vectorize_sentences_with_tfidf(processed_sentences)\n",
        "\n",
        "        # Compute the cosine similarity matrix\n",
        "        similarity_matrix = cosine_similarity_matrix(term_doc_matrix)\n",
        "\n",
        "        # Convert to CPU (NumPy) array for easier handling if necessary\n",
        "        similarity_matrix_cpu = cp.asnumpy(similarity_matrix)\n",
        "\n",
        "        # Store the similarity matrix for the article\n",
        "        similarity_matrices.append(similarity_matrix_cpu)\n",
        "\n",
        "    return similarity_matrices\n",
        "\n",
        "# Enable tqdm for progress bar in pandas apply\n",
        "tqdm.pandas()\n",
        "\n",
        "# Assuming you have a DataFrame `processed_df` with a 'processed_text' column\n",
        "final_similarity_matrices = compute_similarity_for_articles(processed_df, text_column='processed_text')\n",
        "\n",
        "# Example output for the first article\n",
        "print(\"Final Cosine Similarity Matrix for the First Article:\\n\", final_similarity_matrices[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcyWaBI8EbJt",
        "outputId": "6e4ff98e-c9e3-4e53-b35c-60fcacaa25fe"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Articles: 100%|██████████| 11490/11490 [00:37<00:00, 306.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Cosine Similarity Matrix for the First Article:\n",
            " [[1.         0.03550455 0.         0.04097448 0.02367313 0.\n",
            "  0.         0.07210004 0.04264119 0.0403271  0.03092843 0.07493094\n",
            "  0.11954024 0.         0.02426954 0.06009226]\n",
            " [0.03550455 1.         0.         0.03528285 0.02038477 0.\n",
            "  0.08077285 0.02888779 0.03671804 0.         0.08621036 0.03002202\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         1.         0.53670032 0.0884582  0.12443423\n",
            "  0.         0.04675813 0.         0.         0.         0.\n",
            "  0.         0.         0.02943534 0.        ]\n",
            " [0.04097448 0.03528285 0.53670032 1.         0.0548335  0.04404127\n",
            "  0.         0.07770597 0.04237492 0.         0.0307353  0.0346473\n",
            "  0.         0.         0.02793048 0.        ]\n",
            " [0.02367313 0.02038477 0.0884582  0.0548335  1.         0.21782932\n",
            "  0.         0.04489486 0.07925059 0.         0.0574819  0.06479821\n",
            "  0.         0.         0.01613692 0.        ]\n",
            " [0.         0.         0.12443423 0.04404127 0.21782932 1.\n",
            "  0.         0.03605873 0.         0.         0.05588047 0.\n",
            "  0.         0.         0.02269982 0.        ]\n",
            " [0.         0.08077285 0.         0.         0.         0.\n",
            "  1.         0.         0.12116003 0.         0.07036216 0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.07210004 0.02888779 0.04675813 0.07770597 0.04489486 0.03605873\n",
            "  0.         1.         0.03469441 0.03281158 0.02516449 0.06096652\n",
            "  0.09726226 0.         0.04261461 0.04889324]\n",
            " [0.04264119 0.03671804 0.         0.04237492 0.07925059 0.\n",
            "  0.12116003 0.03469441 1.         0.20961611 0.17509282 0.65027417\n",
            "  0.06625581 0.37012367 0.18428376 0.25783397]\n",
            " [0.0403271  0.         0.         0.         0.         0.\n",
            "  0.         0.03281158 0.20961611 1.         0.         0.20548975\n",
            "  0.10174    0.26724307 0.61528663 0.27861123]\n",
            " [0.03092843 0.08621036 0.         0.0307353  0.0574819  0.05588047\n",
            "  0.07036216 0.02516449 0.17509282 0.         1.         0.14316235\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.07493094 0.03002202 0.         0.0346473  0.06479821 0.\n",
            "  0.         0.06096652 0.65027417 0.20548975 0.14316235 1.\n",
            "  0.10108112 0.21769148 0.17119909 0.17992976]\n",
            " [0.11954024 0.         0.         0.         0.         0.\n",
            "  0.         0.09726226 0.06625581 0.10174    0.         0.10108112\n",
            "  1.         0.08447064 0.06122887 0.23285574]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.37012367 0.26724307 0.         0.21769148\n",
            "  0.08447064 1.         0.23494642 0.32871681]\n",
            " [0.02426954 0.         0.02943534 0.02793048 0.01613692 0.02269982\n",
            "  0.         0.04261461 0.18428376 0.61528663 0.         0.17119909\n",
            "  0.06122887 0.23494642 1.         0.34944244]\n",
            " [0.06009226 0.         0.         0.         0.         0.\n",
            "  0.         0.04889324 0.25783397 0.27861123 0.         0.17992976\n",
            "  0.23285574 0.32871681 0.34944244 1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import cupy as cp\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Function to Compute TextRank Scores Using Precomputed Similarity Matrices\n",
        "def compute_text_rank_from_similarity(similarity_matrix, damping_factor=0.85, max_iterations=100, tol=1e-6):\n",
        "\n",
        "    n = similarity_matrix.shape[0]\n",
        "    scores = cp.ones(n) / n  # Initialize scores uniformly\n",
        "    transition_matrix = similarity_matrix / (similarity_matrix.sum(axis=1, keepdims=True) + 1e-10)  # Normalize rows\n",
        "\n",
        "    for _ in range(max_iterations):\n",
        "        new_scores = (1 - damping_factor) / n + damping_factor * cp.dot(transition_matrix.T, scores)\n",
        "        if cp.linalg.norm(new_scores - scores, ord=1) < tol:\n",
        "            break\n",
        "        scores = new_scores\n",
        "\n",
        "    return cp.asnumpy(scores)  # Convert to NumPy for easy handling\n",
        "\n",
        "\n",
        "# Function to Extract Top N Sentences Using Original Text\n",
        "def get_top_sentences_with_original_text(processed_text, original_sentences, scores, top_n=5):\n",
        "\n",
        "    sentences_with_scores = [(idx, scores[idx]) for idx in range(len(scores))]\n",
        "\n",
        "    # Get the top N indices by score\n",
        "    top_indices = sorted(sentences_with_scores, key=lambda x: x[1], reverse=True)[:top_n]\n",
        "\n",
        "    # Sort top indices in chronological order\n",
        "    top_indices_sorted = sorted(top_indices, key=lambda x: x[0])\n",
        "\n",
        "    # Retrieve original sentences using indices\n",
        "    top_sentences = [original_sentences[idx] for idx, _ in top_indices_sorted]\n",
        "    return top_sentences\n",
        "\n",
        "\n",
        "# Main Function to Rank Top Sentences Using Original Text and Precomputed Similarity Matrices\n",
        "def rank_top_sentences_with_original_text(df, similarity_matrices, text_column='processed_text', original_text_column='original_text', top_n=5):\n",
        "\n",
        "    # First, convert the DataFrame to Pandas for sentence tokenization\n",
        "    df_cpu = df.to_pandas()\n",
        "\n",
        "    # Apply sentence tokenization to 'article' column (on CPU)\n",
        "    df_cpu['original_text'] = df_cpu['article'].apply(\n",
        "        lambda x: nltk.sent_tokenize(x)  # Split full article into sentences\n",
        "    )\n",
        "\n",
        "    # Convert back to cuDF for further processing (optional)\n",
        "    df_gpu = cudf.from_pandas(df_cpu)\n",
        "\n",
        "    text_series = df_gpu[text_column].to_pandas()  # Extract processed text\n",
        "    original_text_series = df_gpu[original_text_column].to_pandas()  # Extract original text\n",
        "    all_top_sentences = []\n",
        "\n",
        "    for index, (processed_text, original_sentences, similarity_matrix) in tqdm(\n",
        "        enumerate(zip(text_series, original_text_series, similarity_matrices)),\n",
        "        total=len(similarity_matrices),\n",
        "        desc=\"Ranking Sentences\"\n",
        "    ):\n",
        "        # Compute TextRank scores from the precomputed similarity matrix\n",
        "        text_rank_scores = compute_text_rank_from_similarity(cp.array(similarity_matrix))\n",
        "\n",
        "        # Get the top N sentences using original text\n",
        "        top_sentences = get_top_sentences_with_original_text(\n",
        "            processed_text, original_sentences, text_rank_scores, top_n=top_n\n",
        "        )\n",
        "\n",
        "        # Store the top sentences\n",
        "        all_top_sentences.append(top_sentences)\n",
        "\n",
        "    return all_top_sentences\n",
        "\n",
        "\n",
        "# Compute Top 5 Sentences Using Precomputed Similarity Matrices and Original Sentences\n",
        "top_sentences_per_article = rank_top_sentences_with_original_text(\n",
        "    processed_df, final_similarity_matrices, text_column='processed_text', original_text_column='original_text', top_n=5\n",
        ")\n",
        "\n",
        "# Example Output for the First Article\n",
        "print(\"Top 5 Sentences in Chronological Order for the First Article:\")\n",
        "for rank, sentence in enumerate(top_sentences_per_article[0], start=1):\n",
        "    print(f\"{rank}: {sentence}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMv5ExsiKOih",
        "outputId": "df9d31a4-bbee-487a-cec3-fbedc3a1011f"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ranking Sentences: 100%|██████████| 11490/11490 [04:14<00:00, 45.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 Sentences in Chronological Order for the First Article:\n",
            "1: Tests conducted by the FAA use planes with a 31 inch pitch, a standard which on some airlines has decreased .\n",
            "2: Many economy seats on United Airlines have 30 inches of room, while some airlines offer as little as 28 inches .\n",
            "3: But these tests are conducted using planes with 31 inches between each row of seats, a standard which on some airlines has decreased, reported the Detroit News.\n",
            "4: While United Airlines has 30 inches of space, Gulf Air economy seats have between 29 and 32 inches, Air Asia offers 29 inches and Spirit Airlines offers just 28 inches.\n",
            "5: British Airways has a seat pitch of 31 inches, while easyJet has 29 inches, Thomson's short haul seat pitch is 28 inches, and Virgin Atlantic's is 30-31.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge_score import rouge_scorer\n",
        "\n",
        "# Initialize ROUGE scorer\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "# Create a list to store ROUGE scores for each article\n",
        "rouge_scores = []\n",
        "\n",
        "# Convert cuDF DataFrame to pandas for iteration\n",
        "df_cpu = processed_df.to_pandas()\n",
        "\n",
        "# Iterate over the articles and corresponding summaries\n",
        "for index, row in df_cpu.iterrows():\n",
        "    # Get the reference summary (ground truth) and the generated summary\n",
        "    reference = row['highlights']  # Adjust this column name based on your data\n",
        "    generated_summary = row['extractive_summary']\n",
        "\n",
        "    # Compute ROUGE scores\n",
        "    scores = scorer.score(reference, generated_summary)\n",
        "\n",
        "    # Store the scores in the list\n",
        "    rouge_scores.append(scores)\n",
        "\n",
        "from rouge_score import rouge_scorer\n",
        "import numpy as np\n",
        "\n",
        "# Initialize ROUGE scorer\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "# Create lists to store ROUGE scores for each article\n",
        "rouge1_scores = []\n",
        "rouge2_scores = []\n",
        "rougeL_scores = []\n",
        "\n",
        "# Convert cuDF DataFrame to pandas for iteration\n",
        "df_cpu = processed_df.to_pandas()\n",
        "\n",
        "# Iterate over the articles and corresponding summaries\n",
        "for index, row in df_cpu.iterrows():\n",
        "    # Get the reference summary (ground truth) and the generated summary\n",
        "    reference = row['highlights']  # Adjust this column name based on your data\n",
        "    generated_summary = row['extractive_summary']\n",
        "\n",
        "    # Compute ROUGE scores\n",
        "    scores = scorer.score(reference, generated_summary)\n",
        "\n",
        "    # Store the individual ROUGE scores\n",
        "    rouge1_scores.append(scores['rouge1'])\n",
        "    rouge2_scores.append(scores['rouge2'])\n",
        "    rougeL_scores.append(scores['rougeL'])\n",
        "\n",
        "# Calculate the mean of each ROUGE score (precision, recall, and F-measure)\n",
        "mean_rouge1 = {\n",
        "    'precision': np.mean([score.precision for score in rouge1_scores]),\n",
        "    'recall': np.mean([score.recall for score in rouge1_scores]),\n",
        "    'fmeasure': np.mean([score.fmeasure for score in rouge1_scores])\n",
        "}\n",
        "\n",
        "mean_rouge2 = {\n",
        "    'precision': np.mean([score.precision for score in rouge2_scores]),\n",
        "    'recall': np.mean([score.recall for score in rouge2_scores]),\n",
        "    'fmeasure': np.mean([score.fmeasure for score in rouge2_scores])\n",
        "}\n",
        "\n",
        "mean_rougeL = {\n",
        "    'precision': np.mean([score.precision for score in rougeL_scores]),\n",
        "    'recall': np.mean([score.recall for score in rougeL_scores]),\n",
        "    'fmeasure': np.mean([score.fmeasure for score in rougeL_scores])\n",
        "}\n",
        "\n",
        "# Print the mean ROUGE scores\n",
        "print(\"Mean ROUGE-1 Scores:\", mean_rouge1)\n",
        "print(\"Mean ROUGE-2 Scores:\", mean_rouge2)\n",
        "print(\"Mean ROUGE-L Scores:\", mean_rougeL)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuBF_2hsv4Pc",
        "outputId": "9af25b3b-34e8-40d3-a21e-f58110349bee"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean ROUGE-1 Scores: {'precision': 0.2390871506755061, 'recall': 0.5778617605608724, 'fmeasure': 0.3274576034573056}\n",
            "Mean ROUGE-2 Scores: {'precision': 0.09936520360092581, 'recall': 0.24367598387319003, 'fmeasure': 0.1366565950135189}\n",
            "Mean ROUGE-L Scores: {'precision': 0.15440856725146226, 'recall': 0.379245983189393, 'fmeasure': 0.2124052351617053}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}