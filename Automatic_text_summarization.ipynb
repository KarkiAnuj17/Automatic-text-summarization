{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KarkiAnuj17/Automatic-text-summarization/blob/main/Automatic_text_summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HUshmJtq0hCv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1cea01e-9c85-47ed-a966-dd680852014a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EtxIWDza0kMp"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/dataset.zip\", 'r')\n",
        "zip_ref.extractall(\"/content/dataset\")\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qo35kKPv0kRP"
      },
      "outputs": [],
      "source": [
        "import cudf\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from tqdm import tqdm\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import wordnet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_oX8kZ610kT9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be4636c8-812d-42a3-ddd8-ed55218fe162"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['id', 'article', 'highlights'], dtype='object')\n",
            "(11490, 3)\n"
          ]
        }
      ],
      "source": [
        "path=\"/content/dataset/dataset/test.csv\"\n",
        "df=pd.read_csv(path)\n",
        "print(df.columns)\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wufX14cj0kWa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f388aba-34fe-4caf-8d98-d3a3c52c9f87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6lN5tja0kYz",
        "outputId": "a75f0df2-96dd-4c41-e1b2-fb906271b6f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11490/11490 [07:42<00:00, 24.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                         id  \\\n",
            "0  92c514c913c0bdfe25341af9fd72b29db544099b   \n",
            "1  2003841c7dc0e7c5b1a248f9cd536d727f27a45a   \n",
            "2  91b7d2311527f5c2b63a65ca98d21d9c92485149   \n",
            "3  caabf9cbdf96eb1410295a673e953d304391bfbb   \n",
            "4  3da746a7d9afcaa659088c8366ef6347fe6b53ea   \n",
            "\n",
            "                                             article  \\\n",
            "0  Ever noticed how plane seats appear to be gett...   \n",
            "1  A drunk teenage boy had to be rescued by secur...   \n",
            "2  Dougie Freedman is on the verge of agreeing a ...   \n",
            "3  Liverpool target Neto is also wanted by PSG an...   \n",
            "4  Bruce Jenner will break his silence in a two-h...   \n",
            "\n",
            "                                          highlights  \\\n",
            "0  Experts question if  packed out planes are put...   \n",
            "1  Drunk teenage boy climbed into lion enclosure ...   \n",
            "2  Nottingham Forest are close to extending Dougi...   \n",
            "3  Fiorentina goalkeeper Neto has been linked wit...   \n",
            "4  Tell-all interview with the reality TV star, 6...   \n",
            "\n",
            "                                      processed_text  \n",
            "0  [[ever, notice, plane, seat, appear, get, smal...  \n",
            "1  [[drunk, teenage, boy, rescue, security, jump,...  \n",
            "2  [[dougie, freedman, verge, agree, new, deal, r...  \n",
            "3  [[liverpool, target, neto, also, want, psg, cl...  \n",
            "4  [[bruce, jenner, break, silence, interview, di...  \n"
          ]
        }
      ],
      "source": [
        "def get_wordnet_pos(treebank_tag):\n",
        "    # Map POS tag to WordNet POS tag\n",
        "    if treebank_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif treebank_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif treebank_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif treebank_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Split text into sentences\n",
        "    sentences = sent_tokenize(text)\n",
        "\n",
        "    # Initialize lemmatizer\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "    # Get English stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    # Preprocess each sentence\n",
        "    processed_sentences = []\n",
        "    for sentence in sentences:\n",
        "        # Tokenize words in the sentence\n",
        "        words = word_tokenize(sentence)\n",
        "\n",
        "        # Get POS tags\n",
        "        pos_tags = pos_tag(words)\n",
        "\n",
        "        # Lemmatize and remove stopwords\n",
        "        processed_words = []\n",
        "        for word, pos in pos_tags:\n",
        "            if word.lower() not in stop_words and word.isalnum():\n",
        "                lemmatized_word = lemmatizer.lemmatize(word.lower(), get_wordnet_pos(pos))\n",
        "                processed_words.append(lemmatized_word)\n",
        "\n",
        "        # Append processed sentence\n",
        "        processed_sentences.append(processed_words)\n",
        "\n",
        "    return processed_sentences\n",
        "\n",
        "def preprocess_csv(file_path, text_column):\n",
        "    # Read the CSV file into a cuDF DataFrame\n",
        "    df = cudf.read_csv(file_path)\n",
        "\n",
        "    # Convert text column to a pandas Series for processing with NLTK\n",
        "    text_series = df[text_column].to_pandas()\n",
        "\n",
        "    # Apply preprocessing to the text column with progress bar\n",
        "    processed_text = text_series.progress_apply(preprocess_text)\n",
        "\n",
        "    # Convert the processed text back to a cuDF DataFrame\n",
        "    df['processed_text'] = cudf.from_pandas(processed_text)\n",
        "\n",
        "    return df\n",
        "\n",
        "# Enable the tqdm progress_apply\n",
        "tqdm.pandas()\n",
        "\n",
        "file_path = '/content/dataset/dataset/test.csv'\n",
        "text_column = 'article'\n",
        "processed_df = preprocess_csv(file_path, text_column)\n",
        "\n",
        "# Display the processed DataFrame\n",
        "print(processed_df.head())\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cupy as cp\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Cosine Similarity Function\n",
        "def cosine_similarity_matrix(matrix):\n",
        "    matrix = cp.array(matrix)\n",
        "    dot_product = cp.dot(matrix, matrix.T)  # Compute dot product\n",
        "    norm = cp.linalg.norm(matrix, axis=1)  # Compute norm (magnitude) of each vector\n",
        "    similarity_matrix = dot_product / (cp.outer(norm, norm) + 1e-10)  # Cosine similarity\n",
        "    return similarity_matrix\n",
        "\n",
        "# Vectorization Function using TF-IDF\n",
        "def vectorize_sentences_with_tfidf(sentences):\n",
        "    vectorizer = TfidfVectorizer(stop_words='english')  # Optional: Remove stopwords\n",
        "    term_doc_matrix_cpu = vectorizer.fit_transform(sentences)  # Compute the TF-IDF matrix\n",
        "\n",
        "    # Convert the sparse matrix to a dense NumPy array\n",
        "    term_doc_matrix_cpu = term_doc_matrix_cpu.toarray()\n",
        "\n",
        "    # Convert to CuPy array for GPU acceleration\n",
        "    term_doc_matrix = cp.array(term_doc_matrix_cpu)\n",
        "\n",
        "    return term_doc_matrix\n",
        "\n",
        "# Function to Compute Similarity for Articles\n",
        "def compute_similarity_for_articles(df, text_column='processed_text'):\n",
        "    text_series = df[text_column].to_pandas()  # Get text data from DataFrame\n",
        "    similarity_matrices = []\n",
        "\n",
        "    # Iterate over each article's processed text\n",
        "    for index, processed_text in tqdm(text_series.items(), total=len(text_series), desc=\"Processing Articles\"):\n",
        "\n",
        "        # Ensure processed_text is not empty and is a list of sentences\n",
        "        if processed_text and isinstance(processed_text, list):\n",
        "            processed_sentences = [' '.join(sentence) for sentence in processed_text]  # Join words into sentences\n",
        "        else:\n",
        "            processed_sentences = []\n",
        "\n",
        "        # Skip if the processed_sentences list is empty\n",
        "        if not processed_sentences:\n",
        "            similarity_matrices.append(None)\n",
        "            continue\n",
        "\n",
        "        # Vectorize sentences using TF-IDF approach\n",
        "        term_doc_matrix = vectorize_sentences_with_tfidf(processed_sentences)\n",
        "\n",
        "        # Compute the cosine similarity matrix\n",
        "        similarity_matrix = cosine_similarity_matrix(term_doc_matrix)\n",
        "\n",
        "        # Convert to CPU (NumPy) array for easier handling if necessary\n",
        "        similarity_matrix_cpu = cp.asnumpy(similarity_matrix)\n",
        "\n",
        "        # Store the similarity matrix for the article\n",
        "        similarity_matrices.append(similarity_matrix_cpu)\n",
        "\n",
        "    return similarity_matrices\n",
        "\n",
        "# Enable tqdm for progress bar in pandas apply\n",
        "tqdm.pandas()\n",
        "\n",
        "# Assuming you have a DataFrame `processed_df` with a 'processed_text' column\n",
        "final_similarity_matrices = compute_similarity_for_articles(processed_df, text_column='processed_text')\n",
        "\n",
        "# Example output for the first article\n",
        "print(\"Final Cosine Similarity Matrix for the First Article:\\n\", final_similarity_matrices[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0E5-E7ZnMkum",
        "outputId": "1474e4dd-8070-4e1f-fa6d-285fd6803cac"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Articles: 100%|██████████| 11490/11490 [00:41<00:00, 279.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Cosine Similarity Matrix for the First Article:\n",
            " [[1.         0.03550455 0.         0.04097448 0.02367313 0.\n",
            "  0.         0.07210004 0.04264119 0.0403271  0.03092843 0.07493094\n",
            "  0.11954024 0.         0.02426954 0.06009226]\n",
            " [0.03550455 1.         0.         0.03528285 0.02038477 0.\n",
            "  0.08077285 0.02888779 0.03671804 0.         0.08621036 0.03002202\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         1.         0.53670032 0.0884582  0.12443423\n",
            "  0.         0.04675813 0.         0.         0.         0.\n",
            "  0.         0.         0.02943534 0.        ]\n",
            " [0.04097448 0.03528285 0.53670032 1.         0.0548335  0.04404127\n",
            "  0.         0.07770597 0.04237492 0.         0.0307353  0.0346473\n",
            "  0.         0.         0.02793048 0.        ]\n",
            " [0.02367313 0.02038477 0.0884582  0.0548335  1.         0.21782932\n",
            "  0.         0.04489486 0.07925059 0.         0.0574819  0.06479821\n",
            "  0.         0.         0.01613692 0.        ]\n",
            " [0.         0.         0.12443423 0.04404127 0.21782932 1.\n",
            "  0.         0.03605873 0.         0.         0.05588047 0.\n",
            "  0.         0.         0.02269982 0.        ]\n",
            " [0.         0.08077285 0.         0.         0.         0.\n",
            "  1.         0.         0.12116003 0.         0.07036216 0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.07210004 0.02888779 0.04675813 0.07770597 0.04489486 0.03605873\n",
            "  0.         1.         0.03469441 0.03281158 0.02516449 0.06096652\n",
            "  0.09726226 0.         0.04261461 0.04889324]\n",
            " [0.04264119 0.03671804 0.         0.04237492 0.07925059 0.\n",
            "  0.12116003 0.03469441 1.         0.20961611 0.17509282 0.65027417\n",
            "  0.06625581 0.37012367 0.18428376 0.25783397]\n",
            " [0.0403271  0.         0.         0.         0.         0.\n",
            "  0.         0.03281158 0.20961611 1.         0.         0.20548975\n",
            "  0.10174    0.26724307 0.61528663 0.27861123]\n",
            " [0.03092843 0.08621036 0.         0.0307353  0.0574819  0.05588047\n",
            "  0.07036216 0.02516449 0.17509282 0.         1.         0.14316235\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.07493094 0.03002202 0.         0.0346473  0.06479821 0.\n",
            "  0.         0.06096652 0.65027417 0.20548975 0.14316235 1.\n",
            "  0.10108112 0.21769148 0.17119909 0.17992976]\n",
            " [0.11954024 0.         0.         0.         0.         0.\n",
            "  0.         0.09726226 0.06625581 0.10174    0.         0.10108112\n",
            "  1.         0.08447064 0.06122887 0.23285574]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.37012367 0.26724307 0.         0.21769148\n",
            "  0.08447064 1.         0.23494642 0.32871681]\n",
            " [0.02426954 0.         0.02943534 0.02793048 0.01613692 0.02269982\n",
            "  0.         0.04261461 0.18428376 0.61528663 0.         0.17119909\n",
            "  0.06122887 0.23494642 1.         0.34944244]\n",
            " [0.06009226 0.         0.         0.         0.         0.\n",
            "  0.         0.04889324 0.25783397 0.27861123 0.         0.17992976\n",
            "  0.23285574 0.32871681 0.34944244 1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cupy as cp\n",
        "from tqdm import tqdm\n",
        "\n",
        "# TextRank Function\n",
        "def textrank(sentences, similarity_matrix, damping_factor=0.85, max_iter=100, tol=1e-6):\n",
        "    \"\"\"\n",
        "    Perform TextRank algorithm for ranking sentences.\n",
        "\n",
        "    Parameters:\n",
        "        sentences (list): List of sentences.\n",
        "        similarity_matrix (cupy.ndarray): Precomputed similarity matrix.\n",
        "        damping_factor (float): Damping factor for TextRank algorithm.\n",
        "        max_iter (int): Maximum number of iterations for convergence.\n",
        "        tol (float): Tolerance for convergence.\n",
        "\n",
        "    Returns:\n",
        "        list: List of tuples (sentence, score) sorted by score in descending order.\n",
        "    \"\"\"\n",
        "    n_sentences = len(sentences)\n",
        "    scores = cp.ones(n_sentences) / n_sentences  # Initialize scores uniformly\n",
        "\n",
        "    for _ in range(max_iter):\n",
        "        new_scores = cp.ones(n_sentences) * (1 - damping_factor) / n_sentences\n",
        "        new_scores += damping_factor * cp.dot(similarity_matrix.T, scores)\n",
        "\n",
        "        if cp.linalg.norm(new_scores - scores) < tol:  # Check for convergence\n",
        "            break\n",
        "        scores = new_scores\n",
        "\n",
        "    scores = cp.asnumpy(scores)  # Convert to NumPy for compatibility\n",
        "    ranked_sentences = sorted(zip(sentences, scores), key=lambda x: x[1], reverse=True)\n",
        "    return ranked_sentences\n",
        "\n",
        "# Function to Compute TextRank for Processed Data\n",
        "def compute_textrank_for_articles(processed_df, similarity_matrices, text_column='processed_text'):\n",
        "    \"\"\"\n",
        "    Compute TextRank scores for each article in the processed DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "        processed_df (cudf.DataFrame): DataFrame containing preprocessed text data.\n",
        "        similarity_matrices (list): List of similarity matrices for each article.\n",
        "        text_column (str): Column name containing processed sentences.\n",
        "\n",
        "    Returns:\n",
        "        list: List of ranked sentences with scores for each article.\n",
        "    \"\"\"\n",
        "    text_series = processed_df[text_column].to_pandas()  # Convert to pandas for processing\n",
        "    all_ranked_sentences = []\n",
        "\n",
        "    for idx, (processed_text, similarity_matrix) in tqdm(\n",
        "        enumerate(zip(text_series, similarity_matrices)),\n",
        "        total=len(text_series),\n",
        "        desc=\"Computing TextRank for Articles\"\n",
        "    ):\n",
        "        # Ensure processed_text and similarity_matrix are valid\n",
        "        if not processed_text or similarity_matrix is None:\n",
        "            all_ranked_sentences.append(None)\n",
        "            continue\n",
        "\n",
        "        # Prepare sentences and ensure compatibility\n",
        "        sentences = [' '.join(sentence) for sentence in processed_text]\n",
        "        similarity_matrix = cp.array(similarity_matrix)  # Move similarity matrix to GPU\n",
        "\n",
        "        # Compute TextRank\n",
        "        ranked_sentences = textrank(sentences, similarity_matrix)\n",
        "        all_ranked_sentences.append(ranked_sentences)\n",
        "\n",
        "    return all_ranked_sentences\n",
        "\n",
        "# Assuming you have `processed_df` and `final_similarity_matrices` already available\n",
        "ranked_sentences_per_article = compute_textrank_for_articles(processed_df, final_similarity_matrices)\n",
        "\n",
        "# Output example for the first article\n",
        "print(\"Ranked Sentences for the First Article:\")\n",
        "for sentence, score in ranked_sentences_per_article[0]:\n",
        "    print(f\"Score: {score:.4f} - Sentence: {sentence}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXOVJSfIpGy1",
        "outputId": "576281f5-0e95-44b2-e850-a7ce2138f7d4"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing TextRank for Articles: 100%|██████████| 11490/11490 [18:57<00:00, 10.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ranked Sentences for the First Article:\n",
            "Score: 2087802405223129178469074353520640.0000 - Sentence: test conduct faa use plane 31 inch pitch standard airline decrease\n",
            "Score: 1936359890403713434337974903898112.0000 - Sentence: many economy seat united airline 30 inch room airline offer little 28 inch\n",
            "Score: 1907197179605943111203070238785536.0000 - Sentence: united airline 30 inch space gulf air economy seat 29 32 inch air asia offer 29 inch spirit airline offer 28 inch\n",
            "Score: 1893518571944218732339545421905920.0000 - Sentence: test conduct use plane 31 inch row seat standard airline decrease report detroit news\n",
            "Score: 1815780829574358186266313913008128.0000 - Sentence: british airway seat pitch 31 inch easyjet 29 inch thomson short haul seat pitch 28 inch virgin atlantic\n",
            "Score: 1765594298684167494298801029513216.0000 - Sentence: airline stick pitch 31 inch fall\n",
            "Score: 813647559314011728417479460913152.0000 - Sentence: distance two seat one point seat point seat behind know pitch\n",
            "Score: 445950244032780433708058905935872.0000 - Sentence: cynthia corbertt human factor researcher federal aviation administration conduct test quickly passenger leave plane\n",
            "Score: 390344045642961793639474937200640.0000 - Sentence: ever notice plane seat appear get small small\n",
            "Score: 366445892557721225529335773921280.0000 - Sentence: could crowd plane lead serious issue fight space overhead locker crash elbow seat back kick\n",
            "Score: 264332344674491587449935519285248.0000 - Sentence: week consumer advisory group set department transportation say public hearing government happy set standard animal fly plane stipulate minimum amount space human\n",
            "Score: 230860124437200541505857477672960.0000 - Sentence: squabbling arm rest shrink space plane put health safety danger\n",
            "Score: 185408040197298836619633123917824.0000 - Sentence: time dot faa take stand humane treatment passenger\n",
            "Score: 146468994089600082348514020950016.0000 - Sentence: say shrink space aeroplane uncomfortable put health safety danger\n",
            "Score: 141007710557200214841701850677248.0000 - Sentence: increase number people take sky expert question pack plane put passenger risk\n",
            "Score: 104952334124853892319496051359744.0000 - Sentence: world animal right space food human say charlie leocha consumer representative committee\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cupy as cp\n",
        "from tqdm import tqdm\n",
        "\n",
        "def initialize_centroids(embeddings, n_clusters):\n",
        "    \"\"\"\n",
        "    Randomly initialize centroids for K-means clustering.\n",
        "\n",
        "    Parameters:\n",
        "        embeddings (cupy.ndarray): The sentence embeddings or similarity matrix.\n",
        "        n_clusters (int): The number of clusters to form.\n",
        "\n",
        "    Returns:\n",
        "        cupy.ndarray: Randomly initialized centroids.\n",
        "    \"\"\"\n",
        "    n_samples = embeddings.shape[0]\n",
        "\n",
        "    # Ensure n_clusters does not exceed the number of samples\n",
        "    if n_clusters > n_samples:\n",
        "        n_clusters = n_samples\n",
        "\n",
        "    random_indices = cp.random.choice(n_samples, n_clusters, replace=False)\n",
        "    centroids = embeddings[random_indices]\n",
        "    return centroids\n",
        "\n",
        "def assign_clusters(embeddings, centroids):\n",
        "    \"\"\"\n",
        "    Assign each sentence to the nearest centroid.\n",
        "\n",
        "    Parameters:\n",
        "        embeddings (cupy.ndarray): The sentence embeddings or similarity matrix.\n",
        "        centroids (cupy.ndarray): The centroids for the clusters.\n",
        "\n",
        "    Returns:\n",
        "        cupy.ndarray: Cluster labels for each sentence.\n",
        "    \"\"\"\n",
        "    distances = cp.linalg.norm(embeddings[:, None] - centroids, axis=2)  # Compute pairwise distances\n",
        "    cluster_labels = cp.argmin(distances, axis=1)  # Assign the nearest centroid\n",
        "    return cluster_labels\n",
        "\n",
        "def update_centroids(embeddings, cluster_labels, n_clusters):\n",
        "    \"\"\"\n",
        "    Update centroids by computing the mean of the sentences in each cluster.\n",
        "\n",
        "    Parameters:\n",
        "        embeddings (cupy.ndarray): The sentence embeddings or similarity matrix.\n",
        "        cluster_labels (cupy.ndarray): The current cluster labels for each sentence.\n",
        "        n_clusters (int): The number of clusters.\n",
        "\n",
        "    Returns:\n",
        "        cupy.ndarray: Updated centroids.\n",
        "    \"\"\"\n",
        "    new_centroids = cp.zeros((n_clusters, embeddings.shape[1]))\n",
        "    for i in range(n_clusters):\n",
        "        cluster_points = embeddings[cluster_labels == i]\n",
        "        if len(cluster_points) > 0:\n",
        "            new_centroids[i] = cp.mean(cluster_points, axis=0)\n",
        "        else:\n",
        "            # If the cluster has no points, reinitialize the centroid randomly\n",
        "            random_idx = cp.random.choice(embeddings.shape[0], size=1)  # Specify size=1\n",
        "            new_centroids[i] = embeddings[random_idx]\n",
        "    return new_centroids\n",
        "\n",
        "def kmeans_clustering(embeddings, n_clusters=3, max_iters=100, tol=1e-6):\n",
        "    \"\"\"\n",
        "    Perform K-means clustering on sentence embeddings.\n",
        "\n",
        "    Parameters:\n",
        "        embeddings (cupy.ndarray): The sentence embeddings or similarity matrix.\n",
        "        n_clusters (int): The number of clusters to form.\n",
        "        max_iters (int): Maximum number of iterations to run the K-means algorithm.\n",
        "        tol (float): Tolerance for convergence (when centroids stop changing).\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the final cluster labels and centroids.\n",
        "    \"\"\"\n",
        "    centroids = initialize_centroids(embeddings, n_clusters)\n",
        "\n",
        "    for _ in range(max_iters):\n",
        "        cluster_labels = assign_clusters(embeddings, centroids)\n",
        "        new_centroids = update_centroids(embeddings, cluster_labels, n_clusters)\n",
        "\n",
        "        # Check for convergence (ensure shapes match before comparison)\n",
        "        if new_centroids.shape == centroids.shape and cp.allclose(centroids, new_centroids, atol=tol, rtol=0):\n",
        "            break\n",
        "\n",
        "        centroids = new_centroids\n",
        "\n",
        "    return cluster_labels, centroids\n",
        "\n",
        "# Function to compute K-means clustering on the ranked sentences for each article\n",
        "def compute_kmeans_for_articles(processed_df, similarity_matrices, n_clusters=3, text_column='processed_text'):\n",
        "    \"\"\"\n",
        "    Perform K-means clustering on the ranked sentences of each article.\n",
        "\n",
        "    Parameters:\n",
        "        processed_df (cudf.DataFrame): DataFrame containing preprocessed text data.\n",
        "        similarity_matrices (list): List of similarity matrices for each article.\n",
        "        n_clusters (int): Number of clusters for K-means.\n",
        "        text_column (str): Column name containing processed sentences.\n",
        "\n",
        "    Returns:\n",
        "        list: List of cluster labels for each article's ranked sentences.\n",
        "    \"\"\"\n",
        "    text_series = processed_df[text_column].to_pandas()  # Convert to pandas for processing\n",
        "    all_cluster_labels = []\n",
        "\n",
        "    for idx, (processed_text, similarity_matrix) in tqdm(\n",
        "        enumerate(zip(text_series, similarity_matrices)),\n",
        "        total=len(text_series),\n",
        "        desc=\"Computing K-means for Articles\"\n",
        "    ):\n",
        "        # Ensure processed_text and similarity_matrix are valid\n",
        "        if not processed_text or similarity_matrix is None:\n",
        "            all_cluster_labels.append(None)\n",
        "            continue\n",
        "\n",
        "        # Prepare sentences and ensure compatibility\n",
        "        sentences = [' '.join(sentence) for sentence in processed_text]\n",
        "        similarity_matrix = cp.array(similarity_matrix)  # Move similarity matrix to GPU\n",
        "\n",
        "        # Perform K-means clustering on the similarity matrix (treated as sentence embeddings)\n",
        "        cluster_labels, _ = kmeans_clustering(similarity_matrix, n_clusters=n_clusters)\n",
        "        all_cluster_labels.append(cluster_labels)\n",
        "\n",
        "    return all_cluster_labels\n",
        "\n",
        "# Assuming you have `processed_df` and `final_similarity_matrices` already available\n",
        "cluster_labels_per_article = compute_kmeans_for_articles(processed_df, final_similarity_matrices, n_clusters=3)\n",
        "\n",
        "# Output example for the first article\n",
        "print(\"Cluster Labels for the First Article:\")\n",
        "for idx, label in enumerate(cluster_labels_per_article[0]):\n",
        "    print(f\"Sentence {idx} is in Cluster {label}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gIHTnpTw50v",
        "outputId": "20dc8c52-c400-446e-d5da-9bf2cd53b608"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing K-means for Articles: 100%|██████████| 11490/11490 [02:04<00:00, 92.19it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster Labels for the First Article:\n",
            "Sentence 0 is in Cluster 2\n",
            "Sentence 1 is in Cluster 2\n",
            "Sentence 2 is in Cluster 1\n",
            "Sentence 3 is in Cluster 0\n",
            "Sentence 4 is in Cluster 2\n",
            "Sentence 5 is in Cluster 2\n",
            "Sentence 6 is in Cluster 2\n",
            "Sentence 7 is in Cluster 2\n",
            "Sentence 8 is in Cluster 2\n",
            "Sentence 9 is in Cluster 2\n",
            "Sentence 10 is in Cluster 2\n",
            "Sentence 11 is in Cluster 2\n",
            "Sentence 12 is in Cluster 2\n",
            "Sentence 13 is in Cluster 2\n",
            "Sentence 14 is in Cluster 2\n",
            "Sentence 15 is in Cluster 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import cupy as cp\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import cudf\n",
        "from collections import defaultdict\n",
        "\n",
        "# Function to Compute TextRank Scores Using Precomputed Similarity Matrices\n",
        "def compute_text_rank_from_similarity(similarity_matrix, damping_factor=0.85, max_iterations=100, tol=1e-6):\n",
        "    n = similarity_matrix.shape[0]\n",
        "    scores = cp.ones(n) / n  # Initialize scores uniformly\n",
        "    transition_matrix = similarity_matrix / (similarity_matrix.sum(axis=1, keepdims=True) + 1e-10)  # Normalize rows\n",
        "\n",
        "    for _ in range(max_iterations):\n",
        "        new_scores = (1 - damping_factor) / n + damping_factor * cp.dot(transition_matrix.T, scores)\n",
        "        if cp.linalg.norm(new_scores - scores, ord=1) < tol:\n",
        "            break\n",
        "        scores = new_scores\n",
        "\n",
        "    return cp.asnumpy(scores)  # Convert to NumPy for easy handling\n",
        "\n",
        "\n",
        "# Function to Extract Summary Using Clustering and TextRank\n",
        "def get_summary_by_cluster(processed_text, original_sentences, scores, cluster_labels, summary_length=None):\n",
        "    clusters = defaultdict(list)\n",
        "\n",
        "    # Ensure cluster labels are integers (hashable)\n",
        "    cluster_labels = [int(label) for label in cluster_labels]\n",
        "\n",
        "    # Group sentences by clusters\n",
        "    for idx, score in enumerate(scores):\n",
        "        cluster = cluster_labels[idx]\n",
        "        clusters[cluster].append((idx, score))  # Store (sentence index, score) in the cluster\n",
        "\n",
        "    all_sentences_with_scores = []\n",
        "\n",
        "    # For each cluster, sort the sentences by score\n",
        "    for cluster, sentence_scores in clusters.items():\n",
        "        sentence_scores_sorted = sorted(sentence_scores, key=lambda x: x[1], reverse=True)\n",
        "        all_sentences_with_scores.extend(sentence_scores_sorted)  # Add all sentences in sorted order\n",
        "\n",
        "    # Sort all sentences by score (across all clusters)\n",
        "    all_sentences_with_scores_sorted = sorted(all_sentences_with_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Extract the top sentences based on desired summary length (if given)\n",
        "    if summary_length:\n",
        "        summary_sentences = sorted(all_sentences_with_scores_sorted[:summary_length], key=lambda x: x[0])\n",
        "    else:\n",
        "        # Default strategy: take a proportion of the sentences (e.g., top 30%)\n",
        "        summary_sentences = sorted(all_sentences_with_scores_sorted[:int(len(all_sentences_with_scores_sorted) * 0.3)], key=lambda x: x[0])\n",
        "\n",
        "    # Retrieve the original sentences in chronological order\n",
        "    summary = [original_sentences[idx] for idx, _ in summary_sentences]\n",
        "\n",
        "    return summary\n",
        "\n",
        "\n",
        "# Main Function to Rank Sentences Using Original Text and Precomputed Similarity Matrices with Clustering\n",
        "def generate_summary_with_clustering(df, similarity_matrices, cluster_labels_per_article, text_column='processed_text', original_text_column='original_text', summary_length=None):\n",
        "    # First, convert the DataFrame to Pandas for sentence tokenization\n",
        "    df_cpu = df.to_pandas()\n",
        "\n",
        "    # Apply sentence tokenization to 'article' column (on CPU)\n",
        "    df_cpu['original_text'] = df_cpu['article'].apply(\n",
        "        lambda x: nltk.sent_tokenize(x)  # Split full article into sentences\n",
        "    )\n",
        "\n",
        "    # Convert back to cuDF for further processing (optional)\n",
        "    df_gpu = cudf.from_pandas(df_cpu)\n",
        "\n",
        "    text_series = df_gpu[text_column].to_pandas()  # Extract processed text\n",
        "    original_text_series = df_gpu[original_text_column].to_pandas()  # Extract original text\n",
        "    all_summaries = []\n",
        "\n",
        "    for index, (processed_text, original_sentences, similarity_matrix, cluster_labels) in tqdm(\n",
        "        enumerate(zip(text_series, original_text_series, similarity_matrices, cluster_labels_per_article)),\n",
        "        total=len(similarity_matrices),\n",
        "        desc=\"Generating Summaries\"\n",
        "    ):\n",
        "        # Compute TextRank scores from the precomputed similarity matrix\n",
        "        text_rank_scores = compute_text_rank_from_similarity(cp.array(similarity_matrix))\n",
        "\n",
        "        # Get the summary grouped by clusters\n",
        "        summary = get_summary_by_cluster(\n",
        "            processed_text, original_sentences, text_rank_scores, cluster_labels, summary_length=summary_length\n",
        "        )\n",
        "\n",
        "        # Store the summary\n",
        "        all_summaries.append(summary)\n",
        "\n",
        "    return all_summaries\n",
        "\n",
        "\n",
        "# Example Usage (ensure that `processed_df`, `final_similarity_matrices`, and `cluster_labels_per_article` are defined):\n",
        "generated_summaries = generate_summary_with_clustering(\n",
        "    processed_df, final_similarity_matrices, cluster_labels_per_article, text_column='processed_text', original_text_column='original_text', summary_length=10  # Adjust length as needed\n",
        ")\n",
        "\n",
        "# Output example for the first article (Chronological Order)\n",
        "print(\"Summary for the First Article (Chronological Order):\")\n",
        "for sentence in generated_summaries[0]:\n",
        "    print(sentence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abKfn2rwy5Bi",
        "outputId": "bb07a52f-d325-4f3d-f8fa-1dd0f2e01b04"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating Summaries: 100%|██████████| 11490/11490 [05:09<00:00, 37.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary for the First Article (Chronological Order):\n",
            "They say that the shrinking space on aeroplanes is not only uncomfortable - it's putting our health and safety in danger.\n",
            "More than squabbling over the arm rest, shrinking space on planes putting our health and safety in danger?\n",
            "This week, a U.S consumer advisory group set up by the Department of Transportation said at a public hearing that while the government is happy to set standards for animals flying on planes, it doesn't stipulate a minimum amount of space for humans.\n",
            "Tests conducted by the FAA use planes with a 31 inch pitch, a standard which on some airlines has decreased .\n",
            "Many economy seats on United Airlines have 30 inches of room, while some airlines offer as little as 28 inches .\n",
            "Cynthia Corbertt, a human factors researcher with the Federal Aviation Administration, that it conducts tests on how quickly passengers can leave a plane.\n",
            "But these tests are conducted using planes with 31 inches between each row of seats, a standard which on some airlines has decreased, reported the Detroit News.\n",
            "While most airlines stick to a pitch of 31 inches or above, some fall below this.\n",
            "While United Airlines has 30 inches of space, Gulf Air economy seats have between 29 and 32 inches, Air Asia offers 29 inches and Spirit Airlines offers just 28 inches.\n",
            "British Airways has a seat pitch of 31 inches, while easyJet has 29 inches, Thomson's short haul seat pitch is 28 inches, and Virgin Atlantic's is 30-31.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install -y locales\n",
        "!sudo locale-gen en_US.UTF-8\n",
        "!sudo update-locale LANG=en_US.UTF-8\n",
        "import locale\n",
        "locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')\n",
        "!pip install rouge-score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNeQyR9KagiA",
        "outputId": "a74eb7bc-bd48-472a-8ea5-4d9fd04a64f1"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.82)] [\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.82)] [\r                                                                               \rGet:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:6 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,185 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:10 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,619 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,738 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,514 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,513 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [33.8 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,454 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,224 kB]\n",
            "Fetched 20.7 MB in 2s (9,097 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "locales is already the newest version (2.35-0ubuntu3.8).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 59 not upgraded.\n",
            "Generating locales (this might take a while)...\n",
            "  en_US.UTF-8... done\n",
            "Generation complete.\n",
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (4.66.6)\n",
            "Building wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=659b58c9dc843482df58c7b46530a6e6836b69999d9ba31aeca39649d4e74bea\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.1.2\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}