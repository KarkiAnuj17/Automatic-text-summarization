{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KarkiAnuj17/Automatic-text-summarization/blob/main/Automatic_text_summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUshmJtq0hCv",
        "outputId": "72f88293-90f5-4069-a829-34a491a90c19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EtxIWDza0kMp"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/dataset.zip\", 'r')\n",
        "zip_ref.extractall(\"/content/dataset\")\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qo35kKPv0kRP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "from nltk import pos_tag\n",
        "import cudf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oX8kZ610kT9",
        "outputId": "1d9e87b4-cfaf-40cc-b616-e83e68473ffd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['id', 'article', 'highlights'], dtype='object')\n",
            "(11490, 3)\n"
          ]
        }
      ],
      "source": [
        "path=\"/content/dataset/dataset/test.csv\"\n",
        "df=pd.read_csv(path)\n",
        "print(df.columns)\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wufX14cj0kWa",
        "outputId": "305c1d6d-1f74-4bed-c17e-8cdc9e2626fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6lN5tja0kYz",
        "outputId": "d940d023-43bd-4193-aad0-82a8ef57e4e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11490/11490 [08:10<00:00, 23.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                         id  \\\n",
            "0  92c514c913c0bdfe25341af9fd72b29db544099b   \n",
            "1  2003841c7dc0e7c5b1a248f9cd536d727f27a45a   \n",
            "2  91b7d2311527f5c2b63a65ca98d21d9c92485149   \n",
            "3  caabf9cbdf96eb1410295a673e953d304391bfbb   \n",
            "4  3da746a7d9afcaa659088c8366ef6347fe6b53ea   \n",
            "\n",
            "                                             article  \\\n",
            "0  Ever noticed how plane seats appear to be gett...   \n",
            "1  A drunk teenage boy had to be rescued by secur...   \n",
            "2  Dougie Freedman is on the verge of agreeing a ...   \n",
            "3  Liverpool target Neto is also wanted by PSG an...   \n",
            "4  Bruce Jenner will break his silence in a two-h...   \n",
            "\n",
            "                                          highlights  \\\n",
            "0  Experts question if  packed out planes are put...   \n",
            "1  Drunk teenage boy climbed into lion enclosure ...   \n",
            "2  Nottingham Forest are close to extending Dougi...   \n",
            "3  Fiorentina goalkeeper Neto has been linked wit...   \n",
            "4  Tell-all interview with the reality TV star, 6...   \n",
            "\n",
            "                                      processed_text  \n",
            "0  [[ever, notice, plane, seat, appear, get, smal...  \n",
            "1  [[drunk, teenage, boy, rescue, security, jump,...  \n",
            "2  [[dougie, freedman, verge, agree, new, deal, r...  \n",
            "3  [[liverpool, target, neto, also, want, psg, cl...  \n",
            "4  [[bruce, jenner, break, silence, interview, di...  \n"
          ]
        }
      ],
      "source": [
        "def get_wordnet_pos(treebank_tag):\n",
        "    # Map POS tag to WordNet POS tag\n",
        "    if treebank_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif treebank_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif treebank_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif treebank_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Split text into sentences\n",
        "    sentences = sent_tokenize(text)\n",
        "\n",
        "    # Initialize lemmatizer\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "    # Get English stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    # Preprocess each sentence\n",
        "    processed_sentences = []\n",
        "    for sentence in sentences:\n",
        "        # Tokenize words in the sentence\n",
        "        words = word_tokenize(sentence)\n",
        "\n",
        "        # Get POS tags\n",
        "        pos_tags = pos_tag(words)\n",
        "\n",
        "        # Lemmatize and remove stopwords\n",
        "        processed_words = []\n",
        "        for word, pos in pos_tags:\n",
        "            if word.lower() not in stop_words and word.isalnum():\n",
        "                lemmatized_word = lemmatizer.lemmatize(word.lower(), get_wordnet_pos(pos))\n",
        "                processed_words.append(lemmatized_word)\n",
        "\n",
        "        # Append processed sentence\n",
        "        processed_sentences.append(processed_words)\n",
        "\n",
        "    return processed_sentences\n",
        "\n",
        "def preprocess_csv(file_path, text_column):\n",
        "    # Read the CSV file into a cuDF DataFrame\n",
        "    df = cudf.read_csv(file_path)\n",
        "\n",
        "    # Convert text column to a pandas Series for processing with NLTK\n",
        "    text_series = df[text_column].to_pandas()\n",
        "\n",
        "    # Apply preprocessing to the text column with progress bar\n",
        "    processed_text = text_series.progress_apply(preprocess_text)\n",
        "\n",
        "    # Convert the processed text back to a cuDF DataFrame\n",
        "    df['processed_text'] = cudf.from_pandas(processed_text)\n",
        "\n",
        "    return df\n",
        "\n",
        "# Enable the tqdm progress_apply\n",
        "tqdm.pandas()\n",
        "\n",
        "file_path = '/content/dataset/dataset/test.csv'\n",
        "text_column = 'article'\n",
        "processed_df = preprocess_csv(file_path, text_column)\n",
        "\n",
        "# Display the processed DataFrame\n",
        "print(processed_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0E5-E7ZnMkum",
        "outputId": "5037a473-f7ba-4435-dae9-a75792a06810"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Articles: 100%|██████████| 11490/11490 [00:54<00:00, 210.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Cosine Similarity Matrix for the First Article:\n",
            " [[1.         0.03550455 0.         0.04097448 0.02367313 0.\n",
            "  0.         0.07210004 0.04264119 0.0403271  0.03092843 0.07493094\n",
            "  0.11954024 0.         0.02426954 0.06009226]\n",
            " [0.03550455 1.         0.         0.03528285 0.02038477 0.\n",
            "  0.08077285 0.02888779 0.03671804 0.         0.08621036 0.03002202\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         1.         0.53670032 0.0884582  0.12443423\n",
            "  0.         0.04675813 0.         0.         0.         0.\n",
            "  0.         0.         0.02943534 0.        ]\n",
            " [0.04097448 0.03528285 0.53670032 1.         0.0548335  0.04404127\n",
            "  0.         0.07770597 0.04237492 0.         0.0307353  0.0346473\n",
            "  0.         0.         0.02793048 0.        ]\n",
            " [0.02367313 0.02038477 0.0884582  0.0548335  1.         0.21782932\n",
            "  0.         0.04489486 0.07925059 0.         0.0574819  0.06479821\n",
            "  0.         0.         0.01613692 0.        ]\n",
            " [0.         0.         0.12443423 0.04404127 0.21782932 1.\n",
            "  0.         0.03605873 0.         0.         0.05588047 0.\n",
            "  0.         0.         0.02269982 0.        ]\n",
            " [0.         0.08077285 0.         0.         0.         0.\n",
            "  1.         0.         0.12116003 0.         0.07036216 0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.07210004 0.02888779 0.04675813 0.07770597 0.04489486 0.03605873\n",
            "  0.         1.         0.03469441 0.03281158 0.02516449 0.06096652\n",
            "  0.09726226 0.         0.04261461 0.04889324]\n",
            " [0.04264119 0.03671804 0.         0.04237492 0.07925059 0.\n",
            "  0.12116003 0.03469441 1.         0.20961611 0.17509282 0.65027417\n",
            "  0.06625581 0.37012367 0.18428376 0.25783397]\n",
            " [0.0403271  0.         0.         0.         0.         0.\n",
            "  0.         0.03281158 0.20961611 1.         0.         0.20548975\n",
            "  0.10174    0.26724307 0.61528663 0.27861123]\n",
            " [0.03092843 0.08621036 0.         0.0307353  0.0574819  0.05588047\n",
            "  0.07036216 0.02516449 0.17509282 0.         1.         0.14316235\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.07493094 0.03002202 0.         0.0346473  0.06479821 0.\n",
            "  0.         0.06096652 0.65027417 0.20548975 0.14316235 1.\n",
            "  0.10108112 0.21769148 0.17119909 0.17992976]\n",
            " [0.11954024 0.         0.         0.         0.         0.\n",
            "  0.         0.09726226 0.06625581 0.10174    0.         0.10108112\n",
            "  1.         0.08447064 0.06122887 0.23285574]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.37012367 0.26724307 0.         0.21769148\n",
            "  0.08447064 1.         0.23494642 0.32871681]\n",
            " [0.02426954 0.         0.02943534 0.02793048 0.01613692 0.02269982\n",
            "  0.         0.04261461 0.18428376 0.61528663 0.         0.17119909\n",
            "  0.06122887 0.23494642 1.         0.34944244]\n",
            " [0.06009226 0.         0.         0.         0.         0.\n",
            "  0.         0.04889324 0.25783397 0.27861123 0.         0.17992976\n",
            "  0.23285574 0.32871681 0.34944244 1.        ]]\n"
          ]
        }
      ],
      "source": [
        "import cupy as cp\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Cosine Similarity Function\n",
        "def cosine_similarity_matrix(matrix):\n",
        "    matrix = cp.array(matrix)\n",
        "    dot_product = cp.dot(matrix, matrix.T)  # Compute dot product\n",
        "    norm = cp.linalg.norm(matrix, axis=1)  # Compute norm (magnitude) of each vector\n",
        "    similarity_matrix = dot_product / (cp.outer(norm, norm) + 1e-10)  # Cosine similarity\n",
        "    return similarity_matrix\n",
        "\n",
        "# Vectorization Function using TF-IDF\n",
        "def vectorize_sentences_with_tfidf(sentences):\n",
        "    vectorizer = TfidfVectorizer(stop_words='english')  # Optional: Remove stopwords\n",
        "    term_doc_matrix_cpu = vectorizer.fit_transform(sentences)  # Compute the TF-IDF matrix\n",
        "\n",
        "    # Convert the sparse matrix to a dense NumPy array\n",
        "    term_doc_matrix_cpu = term_doc_matrix_cpu.toarray()\n",
        "\n",
        "    # Convert to CuPy array for GPU acceleration\n",
        "    term_doc_matrix = cp.array(term_doc_matrix_cpu)\n",
        "\n",
        "    return term_doc_matrix\n",
        "\n",
        "# Function to Compute Similarity for Articles\n",
        "def compute_similarity_for_articles(df, text_column='processed_text'):\n",
        "    text_series = df[text_column].to_pandas()  # Get text data from DataFrame\n",
        "    similarity_matrices = []\n",
        "\n",
        "    # Iterate over each article's processed text\n",
        "    for index, processed_text in tqdm(text_series.items(), total=len(text_series), desc=\"Processing Articles\"):\n",
        "\n",
        "        # Ensure processed_text is not empty and is a list of sentences\n",
        "        if processed_text and isinstance(processed_text, list):\n",
        "            processed_sentences = [' '.join(sentence) for sentence in processed_text]  # Join words into sentences\n",
        "        else:\n",
        "            processed_sentences = []\n",
        "\n",
        "        # Skip if the processed_sentences list is empty\n",
        "        if not processed_sentences:\n",
        "            similarity_matrices.append(None)\n",
        "            continue\n",
        "\n",
        "        # Vectorize sentences using TF-IDF approach\n",
        "        term_doc_matrix = vectorize_sentences_with_tfidf(processed_sentences)\n",
        "\n",
        "        # Compute the cosine similarity matrix\n",
        "        similarity_matrix = cosine_similarity_matrix(term_doc_matrix)\n",
        "\n",
        "        # Convert to CPU (NumPy) array for easier handling if necessary\n",
        "        similarity_matrix_cpu = cp.asnumpy(similarity_matrix)\n",
        "\n",
        "        # Store the similarity matrix for the article\n",
        "        similarity_matrices.append(similarity_matrix_cpu)\n",
        "\n",
        "    return similarity_matrices\n",
        "\n",
        "# Enable tqdm for progress bar in pandas apply\n",
        "tqdm.pandas()\n",
        "\n",
        "# Assuming you have a DataFrame `processed_df` with a 'processed_text' column\n",
        "final_similarity_matrices = compute_similarity_for_articles(processed_df, text_column='processed_text')\n",
        "\n",
        "# Example output for the first article\n",
        "print(\"Final Cosine Similarity Matrix for the First Article:\\n\", final_similarity_matrices[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvVrCJR3nrNq",
        "outputId": "12f668ff-aa94-4528-f6aa-ca82bfdc9eba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summary for the First Article:\n",
            " test conduct faa use plane 31 inch pitch standard airline decrease test conduct use plane 31 inch row seat standard airline decrease report detroit news united airline 30 inch space gulf air economy seat 29 32 inch air asia offer 29 inch spirit airline offer 28 inch\n"
          ]
        }
      ],
      "source": [
        "import networkx as nx\n",
        "import numpy as np\n",
        "\n",
        "# Function to build similarity graph\n",
        "def build_similarity_graph(sentences, similarity_matrix):\n",
        "    graph = nx.Graph()\n",
        "    num_sentences = len(sentences)\n",
        "\n",
        "    # Add nodes for all sentences\n",
        "    graph.add_nodes_from(range(num_sentences))\n",
        "\n",
        "    # Add edges for non-zero similarity scores\n",
        "    for i in range(num_sentences):\n",
        "        for j in range(i + 1, num_sentences):\n",
        "            if similarity_matrix[i, j] > 0:  # Add edge if similarity > 0\n",
        "                graph.add_edge(i, j, weight=similarity_matrix[i, j])\n",
        "    return graph\n",
        "\n",
        "# TextRank implementation\n",
        "def textrank_summary(similarity_matrix, sentences, top_n=3):\n",
        "    # Build graph from similarity matrix\n",
        "    graph = build_similarity_graph(sentences, similarity_matrix)\n",
        "\n",
        "    # Apply PageRank algorithm to rank sentences\n",
        "    scores = nx.pagerank(graph)\n",
        "\n",
        "    # Assign default score of 0 for sentences not in the graph\n",
        "    scores = {i: scores.get(i, 0) for i in range(len(sentences))}\n",
        "\n",
        "    # Sort sentences by score\n",
        "    ranked_sentences = sorted(((scores[i], s) for i, s in enumerate(sentences)), reverse=True)\n",
        "\n",
        "    # Extract top-ranked sentences\n",
        "    top_sentences = [sent for _, sent in ranked_sentences[:top_n]]\n",
        "\n",
        "    # Reorder sentences based on original position for coherence\n",
        "    ordered_sentences = sorted(top_sentences, key=lambda s: sentences.index(s))\n",
        "\n",
        "    # Reconstruct the summary\n",
        "    summary = ' '.join(ordered_sentences)\n",
        "    return summary\n",
        "\n",
        "# Generate summaries for all articles\n",
        "def generate_summaries(df, similarity_matrices, top_n=3):\n",
        "    summaries = []\n",
        "    for i, processed_text in enumerate(df['processed_text'].to_pandas()):\n",
        "        if processed_text and similarity_matrices[i] is not None:\n",
        "            sentences = [' '.join(sentence) for sentence in processed_text]\n",
        "            similarity_matrix = similarity_matrices[i]\n",
        "            summary = textrank_summary(similarity_matrix, sentences, top_n)\n",
        "        else:\n",
        "            summary = None\n",
        "        summaries.append(summary)\n",
        "    return summaries\n",
        "\n",
        "# Apply summary generation\n",
        "summaries = generate_summaries(processed_df, final_similarity_matrices)\n",
        "\n",
        "# Example output for the first article\n",
        "print(\"Summary for the First Article:\\n\", summaries[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4m0svUclsgM",
        "outputId": "83e2dce0-9a7e-4977-e9c5-6544cdb91b82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean ROUGE-1 Scores: {'precision': 0.27874620980722675, 'recall': 0.23936717390104828, 'fmeasure': 0.24657258770837462}\n",
            "Mean ROUGE-2 Scores: {'precision': 0.07585856244601576, 'recall': 0.06637691629397806, 'fmeasure': 0.06779815066016259}\n",
            "Mean ROUGE-L Scores: {'precision': 0.2030583887684702, 'recall': 0.17502554704126508, 'fmeasure': 0.17982591290404076}\n"
          ]
        }
      ],
      "source": [
        "from rouge_score import rouge_scorer\n",
        "import numpy as np\n",
        "\n",
        "# Function to calculate ROUGE scores\n",
        "def calculate_rouge(reference_summaries, generated_summaries):\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "    rouge1_scores = []\n",
        "    rouge2_scores = []\n",
        "    rougeL_scores = []\n",
        "\n",
        "    for reference, generated in zip(reference_summaries, generated_summaries):\n",
        "        # Compute ROUGE scores for each pair of reference and generated summary\n",
        "        scores = scorer.score(reference, generated)\n",
        "\n",
        "        # Store individual ROUGE scores\n",
        "        rouge1_scores.append(scores['rouge1'])\n",
        "        rouge2_scores.append(scores['rouge2'])\n",
        "        rougeL_scores.append(scores['rougeL'])\n",
        "\n",
        "    # Calculate the mean ROUGE scores\n",
        "    mean_rouge1 = {\n",
        "        'precision': np.mean([score.precision for score in rouge1_scores]),\n",
        "        'recall': np.mean([score.recall for score in rouge1_scores]),\n",
        "        'fmeasure': np.mean([score.fmeasure for score in rouge1_scores])\n",
        "    }\n",
        "\n",
        "    mean_rouge2 = {\n",
        "        'precision': np.mean([score.precision for score in rouge2_scores]),\n",
        "        'recall': np.mean([score.recall for score in rouge2_scores]),\n",
        "        'fmeasure': np.mean([score.fmeasure for score in rouge2_scores])\n",
        "    }\n",
        "\n",
        "    mean_rougeL = {\n",
        "        'precision': np.mean([score.precision for score in rougeL_scores]),\n",
        "        'recall': np.mean([score.recall for score in rougeL_scores]),\n",
        "        'fmeasure': np.mean([score.fmeasure for score in rougeL_scores])\n",
        "    }\n",
        "\n",
        "    return mean_rouge1, mean_rouge2, mean_rougeL\n",
        "\n",
        "# Step 1: Generate summaries using TextRank\n",
        "summaries = generate_summaries(processed_df, final_similarity_matrices)\n",
        "\n",
        "# Step 2: Extract reference summaries (assuming 'highlights' column contains them)\n",
        "reference_summaries = processed_df['highlights'].to_pandas()\n",
        "\n",
        "# Step 3: Calculate ROUGE scores for the generated summaries\n",
        "mean_rouge1, mean_rouge2, mean_rougeL = calculate_rouge(reference_summaries, summaries)\n",
        "\n",
        "# Step 4: Print the mean ROUGE scores\n",
        "print(\"Mean ROUGE-1 Scores:\", mean_rouge1)\n",
        "print(\"Mean ROUGE-2 Scores:\", mean_rouge2)\n",
        "print(\"Mean ROUGE-L Scores:\", mean_rougeL)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d70tgfAaxqxi",
        "outputId": "e1668d14-0e7e-4ab1-b940-6aaf759980aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence Clusters for the First Document:\n",
            "[2 1 0 0 0 0 4 2 3 3 1 3 2 3 3 3]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.cluster import AgglomerativeClustering\n",
        "import numpy as np\n",
        "\n",
        "# Function to cluster sentences within a document\n",
        "def cluster_sentences(similarity_matrix, n_clusters=5):\n",
        "    # Ensure the similarity matrix is NumPy array\n",
        "    similarity_matrix = np.array(similarity_matrix)\n",
        "\n",
        "    # Convert similarity matrix to distance matrix (1 - similarity)\n",
        "    distance_matrix = 1 - similarity_matrix\n",
        "\n",
        "    # Ensure that the number of clusters does not exceed the number of sentences\n",
        "    n_clusters = min(n_clusters, distance_matrix.shape[0])\n",
        "\n",
        "    # Apply Agglomerative Clustering\n",
        "    clustering_model = AgglomerativeClustering(\n",
        "        n_clusters=n_clusters, metric='precomputed', linkage='average'\n",
        "    )\n",
        "    cluster_labels = clustering_model.fit_predict(distance_matrix)\n",
        "\n",
        "    return cluster_labels\n",
        "\n",
        "# Function to cluster sentences for all documents\n",
        "def cluster_sentences_for_documents(similarity_matrices, n_clusters=5):\n",
        "    sentence_clusters = []\n",
        "\n",
        "    for similarity_matrix in similarity_matrices:\n",
        "        if similarity_matrix is None:\n",
        "            sentence_clusters.append(None)  # Skip if no similarity matrix\n",
        "            continue\n",
        "\n",
        "        # Cluster sentences for the document\n",
        "        clusters = cluster_sentences(similarity_matrix, n_clusters)\n",
        "        sentence_clusters.append(clusters)\n",
        "\n",
        "    return sentence_clusters\n",
        "\n",
        "# Apply clustering to your computed similarity matrices\n",
        "n_clusters = 5  # Number of clusters per document (adjust based on data)\n",
        "sentence_clusters = cluster_sentences_for_documents(final_similarity_matrices, n_clusters=n_clusters)\n",
        "\n",
        "# Example: Display sentence clusters for the first document\n",
        "print(\"Sentence Clusters for the First Document:\")\n",
        "print(sentence_clusters[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utPFQz72C0KL",
        "outputId": "22bf30a1-a53d-43f9-e552-815dff085cc1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Articles: 100%|██████████| 11490/11490 [00:57<00:00, 199.95it/s]\n"
          ]
        }
      ],
      "source": [
        "import networkx as nx\n",
        "import itertools\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Function to generate a word graph from clustered sentences\n",
        "def generate_word_graph(clustered_sentences, processed_sentences, threshold=1):\n",
        "    G = nx.Graph()\n",
        "\n",
        "    # Iterate through each unique cluster index\n",
        "    for cluster_idx in set(clustered_sentences):\n",
        "        # Get sentences belonging to the current cluster\n",
        "        sentences_in_cluster = [processed_sentences[idx] for idx in range(len(clustered_sentences)) if clustered_sentences[idx] == cluster_idx]\n",
        "\n",
        "        # Iterate through each sentence in the cluster\n",
        "        for sentence in sentences_in_cluster:\n",
        "            # Get the unique words in the sentence\n",
        "            words = set(sentence)\n",
        "\n",
        "            # Create edges between all pairs of words in the sentence (undirected graph)\n",
        "            for word1, word2 in itertools.combinations(words, 2):\n",
        "                # Add edge with weight (frequency of co-occurrence)\n",
        "                if G.has_edge(word1, word2):\n",
        "                    G[word1][word2]['weight'] += 1\n",
        "                else:\n",
        "                    G.add_edge(word1, word2, weight=1)\n",
        "\n",
        "    # Remove edges with weight less than the threshold\n",
        "    edges_to_remove = [(u, v) for u, v, data in G.edges(data=True) if data['weight'] < threshold]\n",
        "    G.remove_edges_from(edges_to_remove)\n",
        "\n",
        "    return G\n",
        "\n",
        "# Function to process all articles without visualizing the word graph\n",
        "def process_all_articles(processed_df, sentence_clusters, threshold=1):\n",
        "    # Loop through all articles and process each article\n",
        "    for article_idx in tqdm(range(len(processed_df)), desc=\"Processing Articles\"):\n",
        "        # Get the clustered sentences and processed sentences for the current article\n",
        "        clustered_sentences = sentence_clusters[article_idx]\n",
        "        processed_sentences = processed_df['processed_text'].iloc[article_idx]\n",
        "\n",
        "        # Flatten the processed sentences if needed (flatten each sentence into individual words)\n",
        "        processed_sentences_flattened = [item for sublist in processed_sentences for item in sublist]\n",
        "\n",
        "        # Generate word graph for the clustered sentences\n",
        "        word_graph = generate_word_graph(clustered_sentences, processed_sentences_flattened, threshold)\n",
        "\n",
        "# Example: Process all articles without visualization\n",
        "process_all_articles(processed_df, sentence_clusters, threshold=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6VwjGQaxxeD",
        "outputId": "0b05b20b-6004-48a4-f057-ac4296cdf940"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Articles: 100%|██████████| 11490/11490 [00:49<00:00, 230.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated Summary for the First Article:\n",
            "ever notice plane seat appear get small small increase number people take sky expert question pack plane put passenger risk say shrink space aeroplane uncomfortable put health safety danger squabbling arm rest shrink space plane put health safety danger week consumer advisory group set department transportation say public hearing government happy set standard animal fly plane stipulate minimum amount space human\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import networkx as nx\n",
        "import itertools\n",
        "from collections import Counter\n",
        "from tqdm import tqdm  # Import tqdm for progress bar\n",
        "\n",
        "# Function to generate a word graph from clustered sentences\n",
        "def generate_word_graph(clustered_sentences, processed_sentences, threshold=1):\n",
        "    G = nx.Graph()\n",
        "\n",
        "    # Iterate through each cluster in clustered_sentences\n",
        "    for cluster_idx in clustered_sentences:\n",
        "        # Ensure each cluster is a list of sentences\n",
        "        if isinstance(cluster_idx, list):\n",
        "            for sentence in cluster_idx:\n",
        "                # Ensure the sentence is a list of words\n",
        "                words = set(sentence)\n",
        "\n",
        "                # Create edges between all pairs of words in the sentence (undirected graph)\n",
        "                for word1, word2 in itertools.combinations(words, 2):\n",
        "                    # Add edge with weight (frequency of co-occurrence)\n",
        "                    if G.has_edge(word1, word2):\n",
        "                        G[word1][word2]['weight'] += 1\n",
        "                    else:\n",
        "                        G.add_edge(word1, word2, weight=1)\n",
        "\n",
        "    # Remove edges with weight less than the threshold\n",
        "    edges_to_remove = [(u, v) for u, v, data in G.edges(data=True) if data['weight'] < threshold]\n",
        "    G.remove_edges_from(edges_to_remove)\n",
        "\n",
        "    return G\n",
        "\n",
        "\n",
        "# Function to get the central words based on degree centrality\n",
        "def get_central_words(word_graph, top_n=10):\n",
        "    centrality = nx.degree_centrality(word_graph)\n",
        "    sorted_centrality = sorted(centrality.items(), key=lambda x: x[1], reverse=True)\n",
        "    central_words = [word for word, _ in sorted_centrality[:top_n]]\n",
        "    return central_words\n",
        "\n",
        "\n",
        "# Function to rank sentences based on central word count\n",
        "def rank_sentences_by_central_words(clustered_sentences, processed_sentences, central_words):\n",
        "    sentence_scores = []\n",
        "\n",
        "    for i, sentence in enumerate(processed_sentences):\n",
        "        central_word_count = sum(1 for word in sentence if word in central_words)\n",
        "        sentence_scores.append((i, central_word_count))\n",
        "\n",
        "    # Sort sentences by their centrality (most central words first)\n",
        "    ranked_sentences = sorted(sentence_scores, key=lambda x: x[1], reverse=True)\n",
        "    return ranked_sentences\n",
        "\n",
        "\n",
        "# Function to generate summary based on ranked sentences\n",
        "def generate_summary(ranked_sentences, processed_sentences, top_n_sentences=5):\n",
        "    summary_sentences = [processed_sentences[i] for i, _ in ranked_sentences[:top_n_sentences]]\n",
        "    summary = ' '.join([' '.join(sentence) for sentence in summary_sentences])\n",
        "    return summary\n",
        "\n",
        "\n",
        "# Process all articles and generate summaries\n",
        "def process_all_articles(processed_df, sentence_clusters, top_n_sentences=7, word_graph_threshold=1, central_words_top_n=10):\n",
        "    all_summaries = []\n",
        "\n",
        "    # Use tqdm to add a progress bar to the iteration over the articles\n",
        "    for article_idx in tqdm(range(len(processed_df)), desc=\"Processing Articles\"):\n",
        "        # Get the clustered sentences for the current article\n",
        "        clustered_sentences = sentence_clusters[article_idx]\n",
        "\n",
        "        # Get the processed sentences for the current article\n",
        "        processed_sentences = processed_df['processed_text'].iloc[article_idx]\n",
        "\n",
        "        # Generate word graph for the clustered sentences\n",
        "        word_graph = generate_word_graph(clustered_sentences, processed_sentences, threshold=word_graph_threshold)\n",
        "\n",
        "        # Get the central words from the word graph\n",
        "        central_words = get_central_words(word_graph, top_n=central_words_top_n)\n",
        "\n",
        "        # Rank sentences by their central word count\n",
        "        ranked_sentences = rank_sentences_by_central_words(clustered_sentences, processed_sentences, central_words)\n",
        "\n",
        "        # Generate the summary for the current article\n",
        "        summary = generate_summary(ranked_sentences, processed_sentences, top_n_sentences)\n",
        "\n",
        "        all_summaries.append(summary)\n",
        "\n",
        "    return all_summaries\n",
        "\n",
        "\n",
        "# Example: Generate summaries for all articles in the dataset\n",
        "all_summaries = process_all_articles(processed_df, sentence_clusters, top_n_sentences=5, word_graph_threshold=1, central_words_top_n=10)\n",
        "\n",
        "# Print the generated summary for the first article\n",
        "print(\"Generated Summary for the First Article:\")\n",
        "print(all_summaries[0])  # Only print the summary for the first article\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCLMNARM6gSt",
        "outputId": "f317efb2-52ec-40a7-e355-cbae658cec10"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "100%|██████████| 11490/11490 [01:34<00:00, 121.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated Summary for the First Article (with Proper Sentence Splitting):\n",
            "Ever noticed how plane seats appear to be getting smaller and smaller? With increasing numbers of people taking to the skies, some experts are questioning if having such packed out planes is putting passengers at risk. They say that the shrinking space on aeroplanes is not only uncomfortable - it's putting our health and safety in danger. More than squabbling over the arm rest, shrinking space on planes putting our health and safety in danger? This week, a U.S consumer advisory group set up by the Department of Transportation said at a public hearing that while the government is happy to set standards for animals flying on planes, it doesn't stipulate a minimum amount of space for humans.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Download the punkt tokenizer if not already downloaded\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Function to reconstruct and improve sentence formatting\n",
        "def reconstruct_summary(ranked_sentences, original_sentences, top_n_sentences=7):\n",
        "    \"\"\"\n",
        "    Generate a summary by selecting top-ranked original sentences.\n",
        "\n",
        "    Args:\n",
        "    - ranked_sentences (list): List of tuples (index, score), sorted by score.\n",
        "    - original_sentences (list): List of original sentences from the dataset.\n",
        "    - top_n_sentences (int): Number of top sentences to include in the summary.\n",
        "\n",
        "    Returns:\n",
        "    - str: Final summary text.\n",
        "    \"\"\"\n",
        "    # Check the number of available ranked sentences and limit the selection to that number\n",
        "    max_sentences = min(top_n_sentences, len(ranked_sentences))\n",
        "\n",
        "    # Select the top-ranked original sentences\n",
        "    summary_sentences = []\n",
        "    for i, _ in ranked_sentences[:max_sentences]:\n",
        "        if i < len(original_sentences):  # Ensure the index is valid\n",
        "            sentence = original_sentences[i].strip()  # Strip any extra spaces\n",
        "            if sentence:  # Ensure the sentence is not empty\n",
        "                summary_sentences.append(sentence)\n",
        "\n",
        "    # Join the selected sentences into one final summary text\n",
        "    return ' '.join(summary_sentences)\n",
        "\n",
        "# Function to process all articles in the dataset\n",
        "def process_all_articles(processed_df, sentence_clusters, top_n_sentences=5, word_graph_threshold=1, central_words_top_n=10):\n",
        "    \"\"\"\n",
        "    Process all articles in the dataset to generate summaries using sentence clustering and ranking.\n",
        "\n",
        "    Args:\n",
        "    - processed_df (pd.DataFrame): DataFrame containing processed and original text for each article.\n",
        "    - sentence_clusters (list): Clustering results for sentences of each article.\n",
        "    - top_n_sentences (int): Number of top sentences to include in the summary.\n",
        "    - word_graph_threshold (int): Threshold for word graph edge weight.\n",
        "    - central_words_top_n (int): Number of top central words to consider for ranking sentences.\n",
        "\n",
        "    Returns:\n",
        "    - list: List of summaries for all articles.\n",
        "    \"\"\"\n",
        "    all_summaries = []\n",
        "\n",
        "    for article_idx in tqdm(range(len(processed_df))):  # Use tqdm to display progress for all articles\n",
        "        # Extract clustered sentences and processed sentences for the current article\n",
        "        clustered_sentences = sentence_clusters[article_idx]\n",
        "        processed_sentences = processed_df['processed_text'].iloc[article_idx]\n",
        "\n",
        "        # Use nltk's sentence tokenizer for better sentence splitting\n",
        "        original_sentences = nltk.sent_tokenize(processed_df['article'].iloc[article_idx])\n",
        "\n",
        "        # Flatten the processed sentences\n",
        "        processed_sentences_flattened = [item for sublist in processed_sentences for item in sublist]\n",
        "\n",
        "        # Generate word graph for the clustered sentences\n",
        "        word_graph = generate_word_graph(clustered_sentences, processed_sentences_flattened, threshold=word_graph_threshold)\n",
        "\n",
        "        # Get central words from the word graph\n",
        "        central_words = get_central_words(word_graph, top_n=central_words_top_n)\n",
        "\n",
        "        # Rank sentences based on central words\n",
        "        ranked_sentences = rank_sentences_by_central_words(clustered_sentences, processed_sentences_flattened, central_words)\n",
        "\n",
        "        # Reconstruct summary using original sentences\n",
        "        summary = reconstruct_summary(ranked_sentences, original_sentences, top_n_sentences)\n",
        "        all_summaries.append(summary)\n",
        "\n",
        "    return all_summaries\n",
        "\n",
        "# Example: Process all articles in the dataset and get the summary for the first article\n",
        "all_summaries = process_all_articles(processed_df, sentence_clusters, top_n_sentences=5, word_graph_threshold=1, central_words_top_n=10)\n",
        "\n",
        "# Print the summary for the first article\n",
        "print(\"Generated Summary for the First Article (with Proper Sentence Splitting):\")\n",
        "print(all_summaries[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGFeKTTJx08q",
        "outputId": "700de32a-2363-424f-d841-0f1ecf5389ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.83)] [Waiting for headers] [1\r0% [Connecting to archive.ubuntu.com (185.125.190.83)] [Waiting for headers] [C\r                                                                               \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,636 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:9 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,226 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,550 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,364 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,755 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,469 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,516 kB]\n",
            "Fetched 22.9 MB in 3s (6,746 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "locales is already the newest version (2.35-0ubuntu3.8).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 50 not upgraded.\n",
            "Generating locales (this might take a while)...\n",
            "  en_US.UTF-8... done\n",
            "Generation complete.\n",
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (4.66.6)\n",
            "Building wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=1080d56ba436c857c33911fcaeda9089ae0601ddc3521688f96226948deca788\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.1.2\n"
          ]
        }
      ],
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install -y locales\n",
        "!sudo locale-gen en_US.UTF-8\n",
        "!sudo update-locale LANG=en_US.UTF-8\n",
        "import locale\n",
        "locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')\n",
        "!pip install rouge-score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91bSuIxXx4ZR",
        "outputId": "35e1a97f-62c2-4a50-905c-bfa010a0a95e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 11490/11490 [02:47<00:00, 68.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean ROUGE Scores across all articles:\n",
            "ROUGE-1: Precision: 0.2768, Recall: 0.6299, F-Measure: 0.3728\n",
            "ROUGE-2: Precision: 0.1273, Recall: 0.2939, F-Measure: 0.1722\n",
            "ROUGE-L: Precision: 0.1761, Recall: 0.4073, F-Measure: 0.2384\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from rouge_score import rouge_scorer\n",
        "import nltk\n",
        "\n",
        "# Function to calculate ROUGE scores\n",
        "def calculate_rouge_score(generated_summary, reference_summary):\n",
        "    scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)\n",
        "    scores = scorer.score(reference_summary, generated_summary)\n",
        "    return scores\n",
        "\n",
        "# Function to calculate the mean ROUGE scores across all articles\n",
        "def calculate_mean_rouge_scores(all_rouge_scores):\n",
        "    rouge1_precision, rouge1_recall, rouge1_fmeasure = [], [], []\n",
        "    rouge2_precision, rouge2_recall, rouge2_fmeasure = [], [], []\n",
        "    rougel_precision, rougel_recall, rougel_fmeasure = [], [], []\n",
        "\n",
        "    for rouge_scores in all_rouge_scores:\n",
        "        rouge1_precision.append(rouge_scores['rouge1'].precision)\n",
        "        rouge1_recall.append(rouge_scores['rouge1'].recall)\n",
        "        rouge1_fmeasure.append(rouge_scores['rouge1'].fmeasure)\n",
        "\n",
        "        rouge2_precision.append(rouge_scores['rouge2'].precision)\n",
        "        rouge2_recall.append(rouge_scores['rouge2'].recall)\n",
        "        rouge2_fmeasure.append(rouge_scores['rouge2'].fmeasure)\n",
        "\n",
        "        rougel_precision.append(rouge_scores['rougeL'].precision)\n",
        "        rougel_recall.append(rouge_scores['rougeL'].recall)\n",
        "        rougel_fmeasure.append(rouge_scores['rougeL'].fmeasure)\n",
        "\n",
        "    return {\n",
        "        'rouge1': {\n",
        "            'precision': np.mean(rouge1_precision),\n",
        "            'recall': np.mean(rouge1_recall),\n",
        "            'fmeasure': np.mean(rouge1_fmeasure)\n",
        "        },\n",
        "        'rouge2': {\n",
        "            'precision': np.mean(rouge2_precision),\n",
        "            'recall': np.mean(rouge2_recall),\n",
        "            'fmeasure': np.mean(rouge2_fmeasure)\n",
        "        },\n",
        "        'rougeL': {\n",
        "            'precision': np.mean(rougel_precision),\n",
        "            'recall': np.mean(rougel_recall),\n",
        "            'fmeasure': np.mean(rougel_fmeasure)\n",
        "        }\n",
        "    }\n",
        "\n",
        "# Function to reconstruct and improve sentence formatting\n",
        "def reconstruct_summary(ranked_sentences, original_sentences, top_n_sentences=7):\n",
        "    max_sentences = min(top_n_sentences, len(ranked_sentences))\n",
        "    summary_sentences = []\n",
        "\n",
        "    for i, _ in ranked_sentences[:max_sentences]:\n",
        "        if i < len(original_sentences):  # Ensure the index is valid\n",
        "            sentence = original_sentences[i].strip()  # Strip any extra spaces\n",
        "            if sentence:  # Ensure the sentence is not empty\n",
        "                summary_sentences.append(sentence)\n",
        "\n",
        "    return ' '.join(summary_sentences)\n",
        "\n",
        "# Function to process all articles and calculate ROUGE scores\n",
        "def process_all_articles_and_evaluate(processed_df, sentence_clusters, highlights, top_n_sentences=5, word_graph_threshold=1, central_words_top_n=10):\n",
        "    all_summaries = []\n",
        "    all_rouge_scores = []\n",
        "\n",
        "    for article_idx in tqdm(range(len(processed_df))):  # Iterate over all articles\n",
        "        clustered_sentences = sentence_clusters[article_idx]\n",
        "        processed_sentences = processed_df['processed_text'].iloc[article_idx]\n",
        "        processed_sentences_flattened = [item for sublist in processed_sentences for item in sublist]\n",
        "\n",
        "        # Extract original sentences using nltk's sentence tokenizer\n",
        "        original_sentences = nltk.sent_tokenize(processed_df['article'].iloc[article_idx])\n",
        "\n",
        "        # Generate word graph for clustered sentences\n",
        "        word_graph = generate_word_graph(clustered_sentences, processed_sentences_flattened, threshold=word_graph_threshold)\n",
        "\n",
        "        # Get central words and rank sentences by those central words\n",
        "        central_words = get_central_words(word_graph, top_n=central_words_top_n)\n",
        "        ranked_sentences = rank_sentences_by_central_words(clustered_sentences, processed_sentences_flattened, central_words)\n",
        "\n",
        "        # Reconstruct summary for the current article\n",
        "        generated_summary = reconstruct_summary(ranked_sentences, original_sentences, top_n_sentences)\n",
        "        all_summaries.append(generated_summary)\n",
        "\n",
        "        # Get the reference summary from the highlights of the article\n",
        "        reference_summary = highlights[article_idx]\n",
        "\n",
        "        # Calculate ROUGE scores between generated and reference summaries\n",
        "        rouge_scores = calculate_rouge_score(generated_summary, reference_summary)\n",
        "        all_rouge_scores.append(rouge_scores)\n",
        "\n",
        "    mean_rouge_scores = calculate_mean_rouge_scores(all_rouge_scores)\n",
        "\n",
        "    return all_summaries, all_rouge_scores, mean_rouge_scores\n",
        "\n",
        "# Example: Process all articles and calculate ROUGE scores for each article\n",
        "highlights = processed_df['highlights'].to_arrow().to_pylist()  # Adjusted to use .to_arrow().to_pylist()\n",
        "all_summaries, all_rouge_scores, mean_rouge_scores = process_all_articles_and_evaluate(\n",
        "    processed_df,\n",
        "    sentence_clusters,\n",
        "    highlights,\n",
        "    top_n_sentences=5,\n",
        "    word_graph_threshold=1,\n",
        "    central_words_top_n=10\n",
        ")\n",
        "\n",
        "# Print mean ROUGE scores\n",
        "print(\"Mean ROUGE Scores across all articles:\")\n",
        "print(\"ROUGE-1: Precision: {:.4f}, Recall: {:.4f}, F-Measure: {:.4f}\".format(\n",
        "    mean_rouge_scores['rouge1']['precision'],\n",
        "    mean_rouge_scores['rouge1']['recall'],\n",
        "    mean_rouge_scores['rouge1']['fmeasure']\n",
        "))\n",
        "print(\"ROUGE-2: Precision: {:.4f}, Recall: {:.4f}, F-Measure: {:.4f}\".format(\n",
        "    mean_rouge_scores['rouge2']['precision'],\n",
        "    mean_rouge_scores['rouge2']['recall'],\n",
        "    mean_rouge_scores['rouge2']['fmeasure']\n",
        "))\n",
        "print(\"ROUGE-L: Precision: {:.4f}, Recall: {:.4f}, F-Measure: {:.4f}\".format(\n",
        "    mean_rouge_scores['rougeL']['precision'],\n",
        "    mean_rouge_scores['rougeL']['recall'],\n",
        "    mean_rouge_scores['rougeL']['fmeasure']\n",
        "))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "import cupy as cp\n",
        "\n",
        "def perform_kmeans_clustering(similarity_matrices, max_clusters=3):\n",
        "    \"\"\"\n",
        "    Perform K-Means clustering on similarity matrices.\n",
        "\n",
        "    Parameters:\n",
        "        similarity_matrices (list): List of similarity matrices (one per article).\n",
        "        max_clusters (int): Maximum number of clusters for K-Means.\n",
        "\n",
        "    Returns:\n",
        "        clustered_sentences (list): List of cluster labels for sentences in each article.\n",
        "    \"\"\"\n",
        "    clustered_sentences = []\n",
        "\n",
        "    for sim_matrix in similarity_matrices:\n",
        "        if sim_matrix is not None and len(sim_matrix) > 0:  # Ensure the similarity matrix is valid and not empty\n",
        "            n_sentences = len(sim_matrix)\n",
        "            n_clusters = min(max_clusters, n_sentences)  # Adjust clusters dynamically based on sentence count\n",
        "\n",
        "            if n_clusters < 2:  # Skip clustering if not enough sentences\n",
        "                clustered_sentences.append([0] * n_sentences)  # Assign all sentences to one cluster\n",
        "                continue\n",
        "\n",
        "            # Convert similarity matrix rows to feature vectors\n",
        "            sentence_features = sim_matrix\n",
        "\n",
        "            # Apply K-Means clustering\n",
        "            kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "            cluster_labels = kmeans.fit_predict(sentence_features)\n",
        "\n",
        "            # Append cluster labels for the current article\n",
        "            clustered_sentences.append(cluster_labels)\n",
        "        else:\n",
        "            clustered_sentences.append(None)  # Append None for empty or invalid articles\n",
        "\n",
        "    return clustered_sentences\n",
        "\n",
        "# Perform K-Means clustering for articles\n",
        "max_clusters = 3  # Maximum number of clusters\n",
        "clustered_sentences = perform_kmeans_clustering(final_similarity_matrices, max_clusters=max_clusters)\n",
        "\n",
        "# Example: Display clusters for the first article\n",
        "if clustered_sentences[0] is not None:\n",
        "    print(\"Cluster labels for the first article's sentences:\", clustered_sentences[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARU5FxY8w770",
        "outputId": "2adf6437-46fe-48e7-b1f3-e67367fa69f3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster labels for the first article's sentences: [2 2 0 0 0 0 2 2 1 1 2 1 1 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "from collections import Counter\n",
        "\n",
        "def generate_word_graph(sentences):\n",
        "    \"\"\"\n",
        "    Generate a word graph from a list of tokenized sentences.\n",
        "\n",
        "    Parameters:\n",
        "        sentences (list of lists): Tokenized sentences.\n",
        "\n",
        "    Returns:\n",
        "        graph (networkx.Graph): Word graph.\n",
        "    \"\"\"\n",
        "    graph = nx.Graph()\n",
        "    for sentence in sentences:\n",
        "        for i, word in enumerate(sentence):\n",
        "            for j in range(i + 1, len(sentence)):\n",
        "                graph.add_edge(word, sentence[j])\n",
        "    return graph\n",
        "\n",
        "def get_central_words(word_graph, top_n=10):\n",
        "    \"\"\"\n",
        "    Get the most central words from the word graph using PageRank.\n",
        "\n",
        "    Parameters:\n",
        "        word_graph (networkx.Graph): Word graph.\n",
        "        top_n (int): Number of top central words to retrieve.\n",
        "\n",
        "    Returns:\n",
        "        central_words (list): List of central words.\n",
        "    \"\"\"\n",
        "    pagerank_scores = nx.pagerank(word_graph)\n",
        "    central_words = [word for word, _ in Counter(pagerank_scores).most_common(top_n)]\n",
        "    return central_words\n",
        "\n",
        "def rank_sentences(sentences, central_words):\n",
        "    \"\"\"\n",
        "    Rank sentences based on the occurrence of central words.\n",
        "\n",
        "    Parameters:\n",
        "        sentences (list): List of tokenized sentences.\n",
        "        central_words (list): List of central words.\n",
        "\n",
        "    Returns:\n",
        "        ranked_sentences (list): Ranked list of sentences.\n",
        "    \"\"\"\n",
        "    sentence_scores = []\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        score = sum(1 for word in sentence if word in central_words)\n",
        "        sentence_scores.append((i, score))\n",
        "\n",
        "    # Sort sentences by score in descending order\n",
        "    ranked_sentences = sorted(sentence_scores, key=lambda x: x[1], reverse=True)\n",
        "    return [sentences[i] for i, _ in ranked_sentences]\n",
        "\n",
        "def reconstruct_summary(article, cluster_labels, n_top_sentences=3):\n",
        "    \"\"\"\n",
        "    Generate a reconstructed summary for an article.\n",
        "\n",
        "    Parameters:\n",
        "        article (list of lists): List of tokenized sentences in the article.\n",
        "        cluster_labels (list): Cluster labels for sentences.\n",
        "        n_top_sentences (int): Number of top-ranked sentences per cluster.\n",
        "\n",
        "    Returns:\n",
        "        summary (list): List of reconstructed summary sentences.\n",
        "    \"\"\"\n",
        "    summary = []\n",
        "    unique_clusters = set(cluster_labels)\n",
        "\n",
        "    for cluster in unique_clusters:\n",
        "        # Get sentences in the current cluster\n",
        "        cluster_sentences = [\n",
        "            article[i] for i, label in enumerate(cluster_labels) if label == cluster\n",
        "        ]\n",
        "\n",
        "        if not cluster_sentences:\n",
        "            continue\n",
        "\n",
        "        # Generate word graph for the cluster\n",
        "        word_graph = generate_word_graph(cluster_sentences)\n",
        "\n",
        "        # Get central words\n",
        "        central_words = get_central_words(word_graph)\n",
        "\n",
        "        # Rank sentences within the cluster\n",
        "        ranked_sentences = rank_sentences(cluster_sentences, central_words)\n",
        "\n",
        "        # Add top-ranked sentences to the summary\n",
        "        summary.extend([' '.join(sentence) for sentence in ranked_sentences[:n_top_sentences]])\n",
        "\n",
        "    return summary\n",
        "\n",
        "# Generate summaries for all articles\n",
        "def generate_summaries(processed_df, clustered_sentences, n_top_sentences=3):\n",
        "    \"\"\"\n",
        "    Generate summaries for all articles in the dataset.\n",
        "\n",
        "    Parameters:\n",
        "        processed_df (DataFrame): DataFrame with tokenized and preprocessed text.\n",
        "        clustered_sentences (list): List of cluster labels for all articles.\n",
        "        n_top_sentences (int): Number of top sentences per cluster.\n",
        "\n",
        "    Returns:\n",
        "        processed_df (DataFrame): Updated DataFrame with a 'summary' column.\n",
        "    \"\"\"\n",
        "    all_summaries = []\n",
        "\n",
        "    for i in range(len(processed_df)):\n",
        "        if clustered_sentences[i] is not None:  # Ensure clustering was successful\n",
        "            summary = reconstruct_summary(\n",
        "                article=processed_df['processed_text'].iloc[i],\n",
        "                cluster_labels=clustered_sentences[i],\n",
        "                n_top_sentences=n_top_sentences\n",
        "            )\n",
        "            all_summaries.append('\\n'.join(summary))  # Store the summary as a single string\n",
        "        else:\n",
        "            all_summaries.append(\"Summary not available for this article.\")\n",
        "\n",
        "    processed_df['summary'] = all_summaries\n",
        "    return processed_df\n",
        "\n",
        "# Example usage:\n",
        "n_top_sentences = 3  # Adjust the number of sentences per cluster\n",
        "processed_df = generate_summaries(processed_df, clustered_sentences, n_top_sentences=n_top_sentences)\n",
        "\n",
        "# Display the first few summaries\n",
        "print(processed_df[['article', 'summary']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llVhlkaoyFu_",
        "outputId": "cc4885bb-3744-423e-9314-1ea3fe3c3185"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             article  \\\n",
            "0  Ever noticed how plane seats appear to be gett...   \n",
            "1  A drunk teenage boy had to be rescued by secur...   \n",
            "2  Dougie Freedman is on the verge of agreeing a ...   \n",
            "3  Liverpool target Neto is also wanted by PSG an...   \n",
            "4  Bruce Jenner will break his silence in a two-h...   \n",
            "\n",
            "                                             summary  \n",
            "0  week consumer advisory group set department tr...  \n",
            "1  next level drunk intoxicate rahul kumar 17 cli...  \n",
            "2  dougie freedman verge agree new deal remain no...  \n",
            "3  report neto verbal agreement join serie champi...  \n",
            "4  jenner picture walk back car malibu weekend hi...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if 'summary' in processed_df.columns and not processed_df['summary'].empty:\n",
        "    print(\"First Article Summary:\")\n",
        "    print(processed_df['summary'].iloc[0])\n",
        "else:\n",
        "    print(\"Summary not available for the first article.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Q1dNxBH0LYy",
        "outputId": "ed0bf3d3-75e4-4f6e-a22a-6b0d828ff216"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Article Summary:\n",
            "week consumer advisory group set department transportation say public hearing government happy set standard animal fly plane stipulate minimum amount space human\n",
            "world animal right space food human say charlie leocha consumer representative committee\n",
            "say shrink space aeroplane uncomfortable put health safety danger\n",
            "united airline 30 inch space gulf air economy seat 29 32 inch air asia offer 29 inch spirit airline offer 28 inch\n",
            "british airway seat pitch 31 inch easyjet 29 inch thomson short haul seat pitch 28 inch virgin atlantic\n",
            "many economy seat united airline 30 inch room airline offer little 28 inch\n",
            "could crowd plane lead serious issue fight space overhead locker crash elbow seat back kick\n",
            "increase number people take sky expert question pack plane put passenger risk\n",
            "ever notice plane seat appear get small small\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge_score import rouge_scorer\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "def calculate_rouge_metrics_with_progress(reference_texts, generated_summaries):\n",
        "    \"\"\"\n",
        "    Calculate ROUGE Precision, Recall, and F-Measure for a list of reference texts and generated summaries with progress bar.\n",
        "\n",
        "    Parameters:\n",
        "        reference_texts (list): List of reference summaries (ground truth).\n",
        "        generated_summaries (list): List of generated summaries.\n",
        "\n",
        "    Returns:\n",
        "        mean_metrics (dict): Mean Precision, Recall, and F-Measure for ROUGE-1, ROUGE-2, and ROUGE-L.\n",
        "    \"\"\"\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "    metrics = {\n",
        "        'rouge1': {'precision': [], 'recall': [], 'fmeasure': []},\n",
        "        'rouge2': {'precision': [], 'recall': [], 'fmeasure': []},\n",
        "        'rougeL': {'precision': [], 'recall': [], 'fmeasure': []}\n",
        "    }\n",
        "\n",
        "    # Add a progress bar for the calculation\n",
        "    for reference, generated in tqdm(zip(reference_texts, generated_summaries),\n",
        "                                      total=len(reference_texts),\n",
        "                                      desc=\"Calculating ROUGE Metrics\"):\n",
        "        # Ensure both reference and generated text are valid strings\n",
        "        if isinstance(reference, str) and isinstance(generated, str):\n",
        "            scores = scorer.score(reference, generated)\n",
        "            for rouge_type in metrics.keys():\n",
        "                metrics[rouge_type]['precision'].append(scores[rouge_type].precision)\n",
        "                metrics[rouge_type]['recall'].append(scores[rouge_type].recall)\n",
        "                metrics[rouge_type]['fmeasure'].append(scores[rouge_type].fmeasure)\n",
        "\n",
        "    # Compute mean metrics\n",
        "    mean_metrics = {\n",
        "        rouge_type: {\n",
        "            metric: np.mean(metrics[rouge_type][metric]) for metric in ['precision', 'recall', 'fmeasure']\n",
        "        }\n",
        "        for rouge_type in metrics.keys()\n",
        "    }\n",
        "    return mean_metrics\n",
        "\n",
        "# Prepare reference and generated summaries\n",
        "reference_texts = processed_df['highlights'].to_arrow().to_pylist()\n",
        "generated_summaries = processed_df['summary'].to_arrow().to_pylist()\n",
        "\n",
        "# Compute ROUGE metrics with progress bar\n",
        "mean_rouge_metrics = calculate_rouge_metrics_with_progress(reference_texts, generated_summaries)\n",
        "\n",
        "# Display the results\n",
        "print(\"Mean ROUGE Metrics:\")\n",
        "for rouge_type, scores in mean_rouge_metrics.items():\n",
        "    print(f\"{rouge_type.upper()}:\")\n",
        "    print(f\"  Precision: {scores['precision']:.4f}\")\n",
        "    print(f\"  Recall:    {scores['recall']:.4f}\")\n",
        "    print(f\"  F-Measure: {scores['fmeasure']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5NkUhLX0PbT",
        "outputId": "95aae90b-5bc2-4a5e-e108-8a151bb1a0a5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating ROUGE Metrics: 100%|██████████| 11490/11490 [01:27<00:00, 131.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean ROUGE Metrics:\n",
            "ROUGE1:\n",
            "  Precision: 0.1507\n",
            "  Recall:    0.3841\n",
            "  F-Measure: 0.2102\n",
            "ROUGE2:\n",
            "  Precision: 0.0425\n",
            "  Recall:    0.1103\n",
            "  F-Measure: 0.0595\n",
            "ROUGEL:\n",
            "  Precision: 0.0924\n",
            "  Recall:    0.2396\n",
            "  F-Measure: 0.1295\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}